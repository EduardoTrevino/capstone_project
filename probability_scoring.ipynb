{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation...\n",
      "Simulation complete with 100000 trials.\n",
      "\n",
      "--- Optimal Goal Values ---\n",
      "                 Metric  Multiplier Optimal Goal P(Win in S2) P(Win by S3)\n",
      "                Revenue       700.0      1575.00       29.88%       60.61%\n",
      "  Customer Satisfaction        12.5        28.13       29.88%       60.61%\n",
      "             Reputation         0.3         0.68       29.88%       60.61%\n",
      "Ethical Decision Making         2.0         4.50       29.88%       60.61%\n",
      "            Risk-Taking         2.0         4.50       29.88%       60.61%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. DEFINE CORE GAME PARAMETERS ---\n",
    "\n",
    "# Your heuristic multipliers\n",
    "METRICS = {\n",
    "    'Revenue': {'multiplier': 700, 'max_value': np.inf},\n",
    "    'Customer Satisfaction': {'multiplier': 12.5, 'max_value': 100},\n",
    "    'Reputation': {'multiplier': 0.3, 'max_value': 5},\n",
    "    'Ethical Decision Making': {'multiplier': 2, 'max_value': 100},\n",
    "    'Risk-Taking': {'multiplier': 2, 'max_value': 100},\n",
    "}\n",
    "\n",
    "# Model for the 4 options available at each decision point\n",
    "OPTION_SCORES = np.array([0.75, 0.20, -0.10, -0.60]) # Best, Good, Bad, Worst\n",
    "\n",
    "# Model for player behavior (probability of choosing each option)\n",
    "PLAYER_CHOICE_PROBS = np.array([0.40, 0.30, 0.20, 0.10])\n",
    "\n",
    "# Simulation settings\n",
    "DECISIONS_PER_SCENARIO = 3\n",
    "NUM_SCENARIOS = 3\n",
    "NUM_TRIALS = 100_000 # Number of simulated playthroughs\n",
    "\n",
    "# --- 2. RUN THE MONTE CARLO SIMULATION ---\n",
    "\n",
    "def run_simulation():\n",
    "    \"\"\"\n",
    "    Simulates players making choices over 3 scenarios and returns their cumulative scores.\n",
    "    \"\"\"\n",
    "    # Create a giant array of random choices for all decisions in all trials\n",
    "    # Shape: (NUM_TRIALS, NUM_SCENARIOS, DECISIONS_PER_SCENARIO)\n",
    "    choices = np.random.choice(\n",
    "        OPTION_SCORES,\n",
    "        size=(NUM_TRIALS, NUM_SCENARIOS, DECISIONS_PER_SCENARIO),\n",
    "        p=PLAYER_CHOICE_PROBS\n",
    "    )\n",
    "\n",
    "    # Sum the scores for each scenario to get the total kcChange per scenario\n",
    "    # Shape: (NUM_TRIALS, NUM_SCENARIOS)\n",
    "    scenario_kc_change = choices.sum(axis=2)\n",
    "\n",
    "    # Calculate the cumulative kcChange after each scenario\n",
    "    # Shape: (NUM_TRIALS, NUM_SCENARIOS)\n",
    "    cumulative_kc_change = np.cumsum(scenario_kc_change, axis=1)\n",
    "\n",
    "    return cumulative_kc_change\n",
    "\n",
    "print(\"Running simulation...\")\n",
    "# This will be a (100000, 3) array where columns are S1, S2, S3 cumulative scores\n",
    "cumulative_kc_scores = run_simulation()\n",
    "print(f\"Simulation complete with {NUM_TRIALS} trials.\")\n",
    "\n",
    "# --- 3. FIND THE OPTIMAL GOAL FOR EACH METRIC ---\n",
    "\n",
    "def find_best_goal(metric_name, multiplier, max_val, cumulative_kc_scores):\n",
    "    \"\"\"\n",
    "    Searches for the goal value that best matches the target probabilities.\n",
    "    \"\"\"\n",
    "    # Convert kcChange scores into the metric's actual progress values\n",
    "    progress_s1 = cumulative_kc_scores[:, 0] * multiplier\n",
    "    progress_s2 = cumulative_kc_scores[:, 1] * multiplier\n",
    "    progress_s3 = cumulative_kc_scores[:, 2] * multiplier\n",
    "\n",
    "    # --- Rule 1: Never win in Scenario 1 ---\n",
    "    # The goal MUST be higher than the maximum possible score after S1.\n",
    "    max_s1_score = DECISIONS_PER_SCENARIO * np.max(OPTION_SCORES) * multiplier\n",
    "    min_goal = max_s1_score + 1e-6 # Add a tiny epsilon to be strictly greater\n",
    "\n",
    "    # Define a search range for the goal\n",
    "    # Let's search from the minimum possible goal up to a reasonable maximum\n",
    "    search_range_max = np.percentile(progress_s3, 95) # A reasonable upper bound\n",
    "    candidate_goals = np.linspace(min_goal, search_range_max, 500) # Search 500 points\n",
    "\n",
    "    best_goal = None\n",
    "    min_error = float('inf')\n",
    "\n",
    "    for goal in candidate_goals:\n",
    "        # Check if goal is within the metric's valid range (e.g., Reputation <= 5)\n",
    "        if goal > max_val:\n",
    "            continue\n",
    "\n",
    "        # Calculate win probabilities for this candidate goal\n",
    "        win_s1 = progress_s1 >= goal\n",
    "        win_s2 = (progress_s1 < goal) & (progress_s2 >= goal)\n",
    "        win_s3 = (progress_s2 < goal) & (progress_s3 >= goal)\n",
    "\n",
    "        prob_win_s1 = np.mean(win_s1)\n",
    "        # This MUST be zero based on our min_goal calculation, but we check anyway\n",
    "        if prob_win_s1 > 0:\n",
    "            continue\n",
    "\n",
    "        prob_win_exactly_s2 = np.mean(win_s2)\n",
    "        prob_win_by_s3 = np.mean(win_s2 | win_s3) # Cumulative: win in S2 OR S3\n",
    "\n",
    "        # Calculate the error (how far are we from the targets?)\n",
    "        # Target: P(win in S2) = 0.3, P(win by S3) = 0.7\n",
    "        error = (prob_win_exactly_s2 - 0.30)**2 + (prob_win_by_s3 - 0.70)**2\n",
    "\n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            best_goal = goal\n",
    "            final_probs = (prob_win_exactly_s2, prob_win_by_s3)\n",
    "\n",
    "    return best_goal, final_probs\n",
    "\n",
    "# --- 4. CALCULATE AND DISPLAY RESULTS ---\n",
    "\n",
    "results = []\n",
    "for name, properties in METRICS.items():\n",
    "    multiplier = properties['multiplier']\n",
    "    max_value = properties['max_value']\n",
    "    \n",
    "    goal, (p_win2, p_win_by_3) = find_best_goal(\n",
    "        name, multiplier, max_value, cumulative_kc_scores\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        \"Metric\": name,\n",
    "        \"Multiplier\": multiplier,\n",
    "        \"Optimal Goal\": f\"{goal:.2f}\",\n",
    "        \"P(Win in S2)\": f\"{p_win2:.2%}\", # Target: 30%\n",
    "        \"P(Win by S3)\": f\"{p_win_by_3:.2%}\"  # Target: 70%\n",
    "    })\n",
    "\n",
    "# Display in a clean table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n--- Optimal Goal Values ---\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running core simulation to generate player score distributions...\n",
      "Simulation complete with 100000 trials.\n",
      "\n",
      "--- Optimizing for: Revenue ---\n",
      "Optimization complete for Revenue.\n",
      "--- Optimizing for: Customer Satisfaction ---\n",
      "Optimization complete for Customer Satisfaction.\n",
      "--- Optimizing for: Reputation ---\n",
      "Optimization complete for Reputation.\n",
      "--- Optimizing for: Ethical Decision Making ---\n",
      "Optimization complete for Ethical Decision Making.\n",
      "--- Optimizing for: Risk-Taking ---\n",
      "Optimization complete for Risk-Taking.\n",
      "\n",
      "\n",
      "--- Final Optimized Parameters ---\n",
      "                 Metric Optimal Multiplier Optimal Goal P(Win in S2) P(Win by S3)\n",
      "                Revenue             350.00       805.79       33.87%       69.50%\n",
      "  Customer Satisfaction               6.25        14.39       33.87%       69.50%\n",
      "             Reputation               0.15         0.35       33.87%       69.50%\n",
      "Ethical Decision Making               1.00         2.30       33.87%       69.50%\n",
      "            Risk-Taking               1.00         2.30       33.87%       69.50%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. DEFINE CORE GAME PARAMETERS ---\n",
    "\n",
    "# Initial heuristic multipliers (will be used as a starting point for the search)\n",
    "INITIAL_METRICS = {\n",
    "    'Revenue': {'multiplier': 700, 'max_value': np.inf},\n",
    "    'Customer Satisfaction': {'multiplier': 12.5, 'max_value': 100},\n",
    "    'Reputation': {'multiplier': 0.3, 'max_value': 5},\n",
    "    'Ethical Decision Making': {'multiplier': 2, 'max_value': 100},\n",
    "    'Risk-Taking': {'multiplier': 2, 'max_value': 100},\n",
    "}\n",
    "\n",
    "# Model for the 4 options available at each decision point\n",
    "OPTION_SCORES = np.array([0.75, 0.20, -0.10, -0.60]) # Best, Good, Bad, Worst\n",
    "\n",
    "# Model for player behavior (probability of choosing each option)\n",
    "PLAYER_CHOICE_PROBS = np.array([0.42, 0.35, 0.15, 0.08])\n",
    "\n",
    "# Simulation & Optimization settings\n",
    "DECISIONS_PER_SCENARIO = 3\n",
    "NUM_SCENARIOS = 3\n",
    "NUM_TRIALS = 100_000  # High number for stable results\n",
    "MULTIPLIER_SEARCH_STEPS = 1000 # How many multipliers to test\n",
    "GOAL_SEARCH_STEPS = 200     # How many goals to test per multiplier\n",
    "\n",
    "# Target probabilities\n",
    "TARGET_P_WIN2 = 0.65\n",
    "TARGET_P_WIN_BY_3 = 0.85\n",
    "\n",
    "# --- 2. RUN THE MONTE CARLO SIMULATION (ONCE) ---\n",
    "\n",
    "def run_simulation():\n",
    "    \"\"\"Simulates players making choices and returns their cumulative kcChange scores.\"\"\"\n",
    "    print(\"Running core simulation to generate player score distributions...\")\n",
    "    choices = np.random.choice(\n",
    "        OPTION_SCORES,\n",
    "        size=(NUM_TRIALS, NUM_SCENARIOS, DECISIONS_PER_SCENARIO),\n",
    "        p=PLAYER_CHOICE_PROBS\n",
    "    )\n",
    "    scenario_kc_change = choices.sum(axis=2)\n",
    "    cumulative_kc_change = np.cumsum(scenario_kc_change, axis=1)\n",
    "    print(f\"Simulation complete with {NUM_TRIALS} trials.\\n\")\n",
    "    return cumulative_kc_change\n",
    "\n",
    "# This raw score data is the foundation for all optimizations\n",
    "CUMULATIVE_KC_SCORES = run_simulation()\n",
    "\n",
    "# --- 3. CREATE THE TWO-LEVEL OPTIMIZATION FUNCTION ---\n",
    "\n",
    "def find_best_params(metric_name, initial_multiplier, max_val, cumulative_kc_scores):\n",
    "    \"\"\"\n",
    "    Searches for the best (multiplier, goal) pair to match target probabilities.\n",
    "    \"\"\"\n",
    "    print(f\"--- Optimizing for: {metric_name} ---\")\n",
    "    \n",
    "    # Define a search range for the multiplier around its initial value\n",
    "    # e.g., for 700, search from 350 to 1400\n",
    "    multiplier_range = np.linspace(initial_multiplier * 0.5, initial_multiplier * 5.0, MULTIPLIER_SEARCH_STEPS)\n",
    "    \n",
    "    overall_best = {'error': float('inf')}\n",
    "\n",
    "    # Outer loop: Iterate through candidate multipliers\n",
    "    for mult in multiplier_range:\n",
    "        \n",
    "        # Calculate progress scores for this specific multiplier\n",
    "        progress_s1 = cumulative_kc_scores[:, 0] * mult\n",
    "        progress_s2 = cumulative_kc_scores[:, 1] * mult\n",
    "        progress_s3 = cumulative_kc_scores[:, 2] * mult\n",
    "\n",
    "        # Rule 1: Never win in S1. The goal must be higher than the max possible S1 score.\n",
    "        max_s1_score = DECISIONS_PER_SCENARIO * np.max(OPTION_SCORES) * mult\n",
    "        min_goal = max_s1_score + 1e-6\n",
    "\n",
    "        # If even the minimum possible goal is outside the metric's bounds, this multiplier is invalid.\n",
    "        if min_goal > max_val:\n",
    "            continue\n",
    "\n",
    "        # Define a search range for the goal for this multiplier\n",
    "        search_range_max = np.percentile(progress_s3, 95)\n",
    "        candidate_goals = np.linspace(min_goal, min(search_range_max, max_val), GOAL_SEARCH_STEPS)\n",
    "        \n",
    "        # Inner loop: Find the best goal for the current multiplier\n",
    "        for goal in candidate_goals:\n",
    "            win_s1 = progress_s1 >= goal\n",
    "            win_s2 = (progress_s1 < goal) & (progress_s2 >= goal)\n",
    "            win_s3 = (progress_s2 < goal) & (progress_s3 >= goal)\n",
    "\n",
    "            # This must be 0 based on our min_goal rule\n",
    "            if np.any(win_s1): continue\n",
    "\n",
    "            prob_win_exactly_s2 = np.mean(win_s2)\n",
    "            prob_win_by_s3 = np.mean(win_s2 | win_s3)\n",
    "\n",
    "            # Weighted error function to prioritize hitting targets\n",
    "            error = (prob_win_exactly_s2 - TARGET_P_WIN2)**2 + (prob_win_by_s3 - TARGET_P_WIN_BY_3)**2\n",
    "\n",
    "            if error < overall_best['error']:\n",
    "                overall_best['error'] = error\n",
    "                overall_best['multiplier'] = mult\n",
    "                overall_best['goal'] = goal\n",
    "                overall_best['p_win2'] = prob_win_exactly_s2\n",
    "                overall_best['p_win_by_3'] = prob_win_by_s3\n",
    "\n",
    "    print(f\"Optimization complete for {metric_name}.\")\n",
    "    return overall_best\n",
    "\n",
    "\n",
    "# --- 4. CALCULATE AND DISPLAY RESULTS ---\n",
    "\n",
    "final_results = []\n",
    "for name, properties in INITIAL_METRICS.items():\n",
    "    best_params = find_best_params(\n",
    "        name,\n",
    "        properties['multiplier'],\n",
    "        properties['max_value'],\n",
    "        CUMULATIVE_KC_SCORES\n",
    "    )\n",
    "    \n",
    "    final_results.append({\n",
    "        \"Metric\": name,\n",
    "        \"Optimal Multiplier\": f\"{best_params['multiplier']:.2f}\",\n",
    "        \"Optimal Goal\": f\"{best_params['goal']:.2f}\",\n",
    "        \"P(Win in S2)\": f\"{best_params['p_win2']:.2%}\",\n",
    "        \"P(Win by S3)\": f\"{best_params['p_win_by_3']:.2%}\"\n",
    "    })\n",
    "\n",
    "# Display in a clean table\n",
    "results_df = pd.DataFrame(final_results)\n",
    "print(\"\\n\\n--- Final Optimized Parameters ---\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- 1. DEFINE CORE GAME PARAMETERS ---\n",
    "\n",
    "# Initial heuristic multipliers (will be used as a starting point for the search)\n",
    "INITIAL_METRICS = {\n",
    "    'Revenue': {'multiplier': 700, 'max_value': np.inf},\n",
    "    'Customer Satisfaction': {'multiplier': 12.5, 'max_value': 100},\n",
    "    'Reputation': {'multiplier': 0.3, 'max_value': 5},\n",
    "    'Ethical Decision Making': {'multiplier': 2, 'max_value': 100},\n",
    "    'Risk-Taking': {'multiplier': 2, 'max_value': 100},\n",
    "}\n",
    "\n",
    "# Model for the 4 options available at each decision point\n",
    "OPTION_SCORES = np.array([0.75, 0.20, -0.10, -0.60]) # Best, Good, Bad, Worst\n",
    "OPTION_LABELS = ['Best', 'Good', 'Bad', 'Worst']\n",
    "\n",
    "# Model for player behavior (probability of choosing each option)\n",
    "PLAYER_CHOICE_PROBS = np.array([0.42, 0.35, 0.15, 0.08])\n",
    "\n",
    "# Simulation & Optimization settings\n",
    "DECISIONS_PER_SCENARIO = 3\n",
    "NUM_SCENARIOS = 3\n",
    "NUM_TRIALS = 100_000  # High number for stable results\n",
    "MULTIPLIER_SEARCH_STEPS = 100 # Reduced for faster visualization generation\n",
    "GOAL_SEARCH_STEPS = 100     # Reduced for faster visualization generation\n",
    "\n",
    "# Target probabilities (UPDATED AS PER YOUR REQUEST)\n",
    "TARGET_P_WIN2 = 0.65\n",
    "TARGET_P_WIN_BY_3 = 0.85\n",
    "\n",
    "# --- VISUALIZATION SETUP ---\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"viridis\")\n",
    "\n",
    "# --- VISUALIZATION FUNCTIONS ---\n",
    "\n",
    "def plot_player_choice_probs(probs, labels):\n",
    "    \"\"\"Visualizes the assumed player choice probabilities (Slide 2).\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.barplot(x=labels, y=probs, palette=\"viridis\")\n",
    "    ax.set_title('Visual 1: Modeled Player Behavior', fontsize=16, pad=20)\n",
    "    ax.set_xlabel('Decision Quality', fontsize=12)\n",
    "    ax.set_ylabel('Probability of Choice', fontsize=12)\n",
    "    for index, value in enumerate(probs):\n",
    "        plt.text(index, value + 0.01, f'{value:.0%}', ha='center', va='bottom', fontsize=12, weight='bold')\n",
    "    plt.ylim(0, max(probs) * 1.2)\n",
    "    print(\"Generating Visual 1: Player Choice Probabilities...\")\n",
    "\n",
    "def plot_cumulative_score_distributions(scores):\n",
    "    \"\"\"Visualizes the distribution of player scores over time (Slide 3).\"\"\"\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.kdeplot(scores[:, 0], fill=True, alpha=0.6, label='End of Scenario 1')\n",
    "    sns.kdeplot(scores[:, 1], fill=True, alpha=0.6, label='End of Scenario 2')\n",
    "    sns.kdeplot(scores[:, 2], fill=True, alpha=0.6, label='End of Scenario 3')\n",
    "    plt.title('Visual 2: Distribution of Player Scores Over Time', fontsize=16, pad=20)\n",
    "    plt.xlabel(\"Cumulative Raw Score\", fontsize=12)\n",
    "    plt.ylabel(\"Density of Players\", fontsize=12)\n",
    "    plt.legend()\n",
    "    print(\"Generating Visual 2: Cumulative Score Distributions...\")\n",
    "\n",
    "def plot_knob_effects(scores_s3, optimal_goal, optimal_multiplier):\n",
    "    \"\"\"Visualizes the effect of the Multiplier and Goal 'knobs' (Slide 4).\"\"\"\n",
    "    # Part 1: The Multiplier Effect\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    low_mult = optimal_multiplier * 0.5\n",
    "    high_mult = optimal_multiplier * 2.0\n",
    "    \n",
    "    sns.kdeplot(scores_s3 * low_mult, label=f'Low Multiplier ({low_mult:.2f})', fill=True, alpha=0.5)\n",
    "    sns.kdeplot(scores_s3 * optimal_multiplier, label=f'Optimal Multiplier ({optimal_multiplier:.2f})', fill=True, alpha=0.7)\n",
    "    sns.kdeplot(scores_s3 * high_mult, label=f'High Multiplier ({high_mult:.2f})', fill=True, alpha=0.5)\n",
    "    \n",
    "    plt.title('Visual 3a: The \"Multiplier\" Knob Stretches Player Scores', fontsize=14, pad=15)\n",
    "    plt.xlabel('Metric Score (e.g., Revenue)', fontsize=12)\n",
    "    plt.ylabel('Density', fontsize=12)\n",
    "    plt.legend()\n",
    "\n",
    "    # Part 2: The Goal Effect\n",
    "    plt.subplot(2, 1, 2)\n",
    "    final_scores = scores_s3 * optimal_multiplier\n",
    "    sns.kdeplot(final_scores, fill=True, label='Final Score Distribution')\n",
    "    plt.axvline(x=optimal_goal, color='red', linestyle='--', linewidth=2, label=f'Optimal Goal ({optimal_goal:.2f})')\n",
    "    \n",
    "    plt.title('Visual 3b: The \"Goal\" Knob Sets the Winning Threshold', fontsize=14, pad=15)\n",
    "    plt.xlabel('Metric Score (e.g., Revenue)', fontsize=12)\n",
    "    plt.ylabel('Density', fontsize=12)\n",
    "    \n",
    "    # Add text annotations\n",
    "    ylim = plt.gca().get_ylim()\n",
    "    plt.text(optimal_goal * 0.98, ylim[1] * 0.7, 'Did Not Win Yet', ha='right', fontsize=12, color='maroon')\n",
    "    plt.text(optimal_goal * 1.02, ylim[1] * 0.7, 'Win!', ha='left', fontsize=12, color='darkgreen')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.tight_layout(pad=3.0)\n",
    "    print(\"Generating Visual 3: 'Knob' Effects...\")\n",
    "\n",
    "def plot_optimization_heatmap(heatmap_data, best_params):\n",
    "    \"\"\"Visualizes the search for the best parameters (Slide 5).\"\"\"\n",
    "    if heatmap_data.empty:\n",
    "        print(\"Could not generate heatmap: no valid (multiplier, goal) pairs found.\")\n",
    "        return\n",
    "        \n",
    "    # Pivot the data to create a 2D grid of errors\n",
    "    error_pivot = heatmap_data.pivot(index='goal', columns='multiplier', values='error')\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = sns.heatmap(error_pivot, cmap=\"cividis_r\", cbar_kws={'label': 'Error (Lower is Better)'})\n",
    "    ax.set_title('Visual 4: Searching for the Lowest Error', fontsize=16, pad=20)\n",
    "    ax.set_xlabel('Multiplier Tested', fontsize=12)\n",
    "    ax.set_ylabel('Goal Tested', fontsize=12)\n",
    "    \n",
    "    # Find the integer index locations for the best parameters to plot a marker\n",
    "    best_mult_loc = np.argmin(np.abs(error_pivot.columns - best_params['multiplier']))\n",
    "    best_goal_loc = np.argmin(np.abs(error_pivot.index - best_params['goal']))\n",
    "\n",
    "    plt.scatter(best_mult_loc + 0.5, best_goal_loc + 0.5, marker='*', s=500, color='red', edgecolor='white', label='Optimal Point')\n",
    "    \n",
    "    plt.legend()\n",
    "    print(\"Generating Visual 4: Optimization Heatmap...\")\n",
    "\n",
    "\n",
    "# --- 2. RUN THE MONTE CARLO SIMULATION (ONCE) ---\n",
    "\n",
    "def run_simulation():\n",
    "    \"\"\"Simulates players making choices and returns their cumulative kcChange scores.\"\"\"\n",
    "    print(\"Running core simulation to generate player score distributions...\")\n",
    "    choices = np.random.choice(\n",
    "        OPTION_SCORES,\n",
    "        size=(NUM_TRIALS, NUM_SCENARIOS, DECISIONS_PER_SCENARIO),\n",
    "        p=PLAYER_CHOICE_PROBS\n",
    "    )\n",
    "    scenario_kc_change = choices.sum(axis=2)\n",
    "    cumulative_kc_change = np.cumsum(scenario_kc_change, axis=1)\n",
    "    print(f\"Simulation complete with {NUM_TRIALS} trials.\\n\")\n",
    "    return cumulative_kc_change\n",
    "\n",
    "# --- 3. CREATE THE TWO-LEVEL OPTIMIZATION FUNCTION (MODIFIED FOR VISUALIZATION) ---\n",
    "\n",
    "def find_best_params(metric_name, initial_multiplier, max_val, cumulative_kc_scores):\n",
    "    \"\"\"\n",
    "    Searches for the best (multiplier, goal) pair and returns data for heatmap.\n",
    "    \"\"\"\n",
    "    print(f\"--- Optimizing for: {metric_name} ---\")\n",
    "    \n",
    "    multiplier_range = np.linspace(initial_multiplier * 0.5, initial_multiplier * 5.0, MULTIPLIER_SEARCH_STEPS)\n",
    "    \n",
    "    overall_best = {'error': float('inf')}\n",
    "    all_results = [] # Store all results for the heatmap\n",
    "\n",
    "    for mult in multiplier_range:\n",
    "        progress_s1 = cumulative_kc_scores[:, 0] * mult\n",
    "        progress_s2 = cumulative_kc_scores[:, 1] * mult\n",
    "        progress_s3 = cumulative_kc_scores[:, 2] * mult\n",
    "\n",
    "        max_s1_score = DECISIONS_PER_SCENARIO * np.max(OPTION_SCORES) * mult\n",
    "        min_goal = max_s1_score + 1e-6\n",
    "        if min_goal > max_val: continue\n",
    "\n",
    "        search_range_max = np.percentile(progress_s3, 99) # Use 99th percentile for broader search\n",
    "        candidate_goals = np.linspace(min_goal, min(search_range_max, max_val), GOAL_SEARCH_STEPS)\n",
    "        \n",
    "        for goal in candidate_goals:\n",
    "            if goal <= min_goal: continue # Ensure goal is valid\n",
    "            \n",
    "            win_s2 = (progress_s1 < goal) & (progress_s2 >= goal)\n",
    "            win_s3 = (progress_s2 < goal) & (progress_s3 >= goal)\n",
    "\n",
    "            prob_win_exactly_s2 = np.mean(win_s2)\n",
    "            prob_win_by_s3 = np.mean(win_s2 | win_s3)\n",
    "\n",
    "            error = (prob_win_exactly_s2 - TARGET_P_WIN2)**2 + (prob_win_by_s3 - TARGET_P_WIN_BY_3)**2\n",
    "\n",
    "            # Store result for heatmap\n",
    "            all_results.append({'multiplier': mult, 'goal': goal, 'error': error})\n",
    "\n",
    "            if error < overall_best['error']:\n",
    "                overall_best = {\n",
    "                    'error': error, 'multiplier': mult, 'goal': goal,\n",
    "                    'p_win2': prob_win_exactly_s2, 'p_win_by_3': prob_win_by_s3\n",
    "                }\n",
    "\n",
    "    print(f\"Optimization complete for {metric_name}.\")\n",
    "    return overall_best, pd.DataFrame(all_results)\n",
    "\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "if __name__ == \"__main__\":\n",
    "    # This raw score data is the foundation for all optimizations\n",
    "    CUMULATIVE_KC_SCORES = run_simulation()\n",
    "\n",
    "    # --- Generate Core Visuals ---\n",
    "    plot_player_choice_probs(PLAYER_CHOICE_PROBS, OPTION_LABELS)\n",
    "    plot_cumulative_score_distributions(CUMULATIVE_KC_SCORES)\n",
    "\n",
    "    # --- Run Optimization and Generate Metric-Specific Visuals ---\n",
    "    final_results = []\n",
    "    \n",
    "    # We will generate the detailed visuals only for the first metric ('Revenue')\n",
    "    # as an example for the stakeholders.\n",
    "    first_metric = True\n",
    "    \n",
    "    for name, properties in INITIAL_METRICS.items():\n",
    "        best_params, heatmap_df = find_best_params(\n",
    "            name,\n",
    "            properties['multiplier'],\n",
    "            properties['max_value'],\n",
    "            CUMULATIVE_KC_SCORES\n",
    "        )\n",
    "        \n",
    "        if best_params['error'] == float('inf'):\n",
    "            print(f\"\\nCould not find a solution for {name}. It might be impossible to meet the targets with the given constraints.\")\n",
    "            continue\n",
    "            \n",
    "        # For the first metric, generate the detailed \"how it works\" plots\n",
    "        if first_metric:\n",
    "            plot_knob_effects(CUMULATIVE_KC_SCORES[:, 2], best_params['goal'], best_params['multiplier'])\n",
    "            plot_optimization_heatmap(heatmap_df, best_params)\n",
    "            first_metric = False\n",
    "\n",
    "        final_results.append({\n",
    "            \"Metric\": name,\n",
    "            \"Optimal Multiplier\": f\"{best_params['multiplier']:.2f}\",\n",
    "            \"Optimal Goal\": f\"{best_params['goal']:.2f}\",\n",
    "            \"Result P(Win in S2)\": f\"{best_params['p_win2']:.2%}\",\n",
    "            \"Target P(Win in S2)\": f\"{TARGET_P_WIN2:.2%}\",\n",
    "            \"Result P(Win by S3)\": f\"{best_params['p_win_by_3']:.2%}\",\n",
    "            \"Target P(Win by S3)\": f\"{TARGET_P_WIN_BY_3:.2%}\",\n",
    "        })\n",
    "\n",
    "    # Display final results in a clean table\n",
    "    if final_results:\n",
    "        results_df = pd.DataFrame(final_results)\n",
    "        print(\"\\n\\n--- Final Optimized Parameters (Visual 5: The Results Table) ---\")\n",
    "        print(results_df.to_string(index=False))\n",
    "    \n",
    "    # Show all generated plots\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
