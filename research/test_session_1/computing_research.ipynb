{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "import json\n",
    "from io import BytesIO\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse as up\n",
    "\n",
    "uri = \"hidden\"\n",
    "result = up.urlparse(uri)\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": result.path.lstrip(\"/\"),          # 'postgres'\n",
    "    \"user\":   result.username,                  # 'postgres'\n",
    "    \"password\": result.password,                # 'MY_SECRET_PASSWORD'\n",
    "    \"host\":   result.hostname,                  # 'db.abcd1234.supabase.co'\n",
    "    \"port\":   result.port or 5432\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of participant names you want to generate reports for\n",
    "PARTICIPANT_NAMES = [f'P{i}' for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_connection():\n",
    "    \"\"\"Establishes and returns a database connection.\"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        return conn\n",
    "    except psycopg2.OperationalError as e:\n",
    "        print(f\"Error: Could not connect to the database. Please check DB_CONFIG.\")\n",
    "        print(f\"Details: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_lookup_data(conn):\n",
    "    \"\"\"Fetches static data like KC names, Goal names, etc., into dictionaries for easy lookup.\"\"\"\n",
    "    print(\"Fetching lookup data (KCs, Goals, Metrics)...\")\n",
    "    kcs = pd.read_sql(\"SELECT id, kc_identifier, name FROM kcs\", conn).set_index('id').to_dict('index')\n",
    "    goals = pd.read_sql(\"SELECT id, name, description FROM goals\", conn).set_index('id').to_dict('index')\n",
    "    metrics = pd.read_sql(\"SELECT id, name FROM metrics\", conn).set_index('id').to_dict('index')\n",
    "    return {\"kcs\": kcs, \"goals\": goals, \"metrics\": metrics}\n",
    "\n",
    "def create_metric_plot(df_metric_history, lookup_tables):\n",
    "    \"\"\"Creates a line chart of metric performance over decisions and returns it as an image stream.\"\"\"\n",
    "    if df_metric_history.empty:\n",
    "        return None\n",
    "\n",
    "    # <<< FIX: Ensure 'value' column is numeric\n",
    "    df_metric_history['value'] = pd.to_numeric(df_metric_history['value'], errors='coerce')\n",
    "    df_metric_history.dropna(subset=['value'], inplace=True)\n",
    "    \n",
    "    # Replace metric_id with metric_name for the legend\n",
    "    df_metric_history['metric_name'] = df_metric_history['metric_id'].apply(lambda x: lookup_tables['metrics'].get(x, {}).get('name', f'Metric {x}'))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    \n",
    "    # Pivot data to plot each metric as a separate line\n",
    "    pivot_df = df_metric_history.pivot_table(index='decision_number', columns='metric_name', values='value', aggfunc='last')\n",
    "    pivot_df.plot(kind='line', marker='o', ax=ax)\n",
    "    \n",
    "    ax.set_title(\"Metric Performance Over Decisions\")\n",
    "    ax.set_xlabel(\"Decision Number\")\n",
    "    ax.set_ylabel(\"Metric Value\")\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax.legend(title='Metrics')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot to a memory buffer\n",
    "    img_buffer = BytesIO()\n",
    "    plt.savefig(img_buffer, format='png')\n",
    "    img_buffer.seek(0)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return img_buffer\n",
    "\n",
    "def parse_and_plot_kcs(dialogue_history_json, target_kcs, lookup_tables):\n",
    "    \"\"\"Parses dialogue history to track KC scores and generates a plot.\"\"\"\n",
    "    if not dialogue_history_json:\n",
    "        return None, \"No dialogue history available for this goal.\"\n",
    "\n",
    "    # Initialize progress tracker\n",
    "    kc_progress = {kc_id: [0] for kc_id in target_kcs}\n",
    "    \n",
    "    try:\n",
    "        # Loop through the conversation turns\n",
    "        for i, turn in enumerate(dialogue_history_json):\n",
    "            if turn.get('role') == 'user' and 'User chose decision index' in turn.get('content', ''):\n",
    "                decision_index_str = turn['content'].split(': ')[-1].split(':')[0].strip() # Handle cases like \"User chose decision index: 0: '...'\"\n",
    "                decision_index = int(decision_index_str)\n",
    "                \n",
    "                # The assistant's turn with the question is the one before the user's choice\n",
    "                assistant_turn = dialogue_history_json[i-1]\n",
    "                assistant_content = json.loads(assistant_turn['content'])\n",
    "                \n",
    "                options = assistant_content.get('decisionPoint', {}).get('options', [])\n",
    "                if decision_index < len(options):\n",
    "                    chosen_option = options[decision_index]\n",
    "                    kc_impacts = chosen_option.get('kc_impacts', [])\n",
    "                    \n",
    "                    # Update scores for all KCs before applying new impact\n",
    "                    for kc_id in kc_progress:\n",
    "                        last_score = kc_progress[kc_id][-1]\n",
    "                        kc_progress[kc_id].append(last_score)\n",
    "\n",
    "                    # Apply the new impacts\n",
    "                    for impact in kc_impacts:\n",
    "                        kc_identifier = impact['kc_identifier']\n",
    "                        score_change = impact.get('score', 0)\n",
    "                        \n",
    "                        # Find the kc_id from the identifier\n",
    "                        for k_id, k_info in lookup_tables['kcs'].items():\n",
    "                            if k_info['kc_identifier'] == kc_identifier:\n",
    "                                if k_id in kc_progress:\n",
    "                                    kc_progress[k_id][-1] += score_change\n",
    "                                break\n",
    "\n",
    "    except (json.JSONDecodeError, KeyError, IndexError, TypeError, ValueError) as e:\n",
    "        return None, f\"Could not parse KC data from dialogue history. Error: {e}\"\n",
    "\n",
    "    if not any(len(v) > 1 for v in kc_progress.values()):\n",
    "        return None, \"No scorable KC decisions were made in this goal.\"\n",
    "\n",
    "    # Prepare DataFrame for plotting\n",
    "    plot_data = []\n",
    "    for kc_id, scores in kc_progress.items():\n",
    "        kc_name = lookup_tables['kcs'].get(kc_id, {}).get('name', f'KC {kc_id}')\n",
    "        for i, score in enumerate(scores):\n",
    "            plot_data.append({'decision': i, 'kc_name': kc_name, 'score': score})\n",
    "    \n",
    "    df_plot = pd.DataFrame(plot_data)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    pivot_df = df_plot.pivot_table(index='decision', columns='kc_name', values='score')\n",
    "    pivot_df.plot(kind='line', marker='o', ax=ax)\n",
    "    \n",
    "    ax.set_title(\"Knowledge Component (KC) Learning Curve\")\n",
    "    ax.set_xlabel(\"Decision Number\")\n",
    "    ax.set_ylabel(\"Cumulative KC Score\")\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax.legend(title='Knowledge Components')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    img_buffer = BytesIO()\n",
    "    plt.savefig(img_buffer, format='png')\n",
    "    img_buffer.seek(0)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return img_buffer, \"KC learning curve generated.\"\n",
    "\n",
    "\n",
    "def add_decision_path_to_doc(doc, dialogue_history_json, lookup_tables):\n",
    "    \"\"\"Parses dialogue history and adds the decision path to the Word document.\"\"\"\n",
    "    if not dialogue_history_json:\n",
    "        doc.add_paragraph(\"No dialogue history available.\")\n",
    "        return\n",
    "        \n",
    "    doc.add_heading(\"C. Decision Path & Rationale\", level=3)\n",
    "    \n",
    "    decision_counter = 1\n",
    "    try:\n",
    "        for i, turn in enumerate(dialogue_history_json):\n",
    "            if turn.get('role') == 'assistant':\n",
    "                assistant_content = json.loads(turn['content'])\n",
    "                decision_point = assistant_content.get('decisionPoint')\n",
    "                if decision_point and 'question' in decision_point and i + 1 < len(dialogue_history_json):\n",
    "                    # This is a question turn. The user's answer is next.\n",
    "                    user_turn = dialogue_history_json[i+1]\n",
    "                    if 'User chose decision index' in user_turn.get('content', ''):\n",
    "                        decision_index_str = user_turn['content'].split(': ')[-1].split(':')[0].strip() # Handle cases like \"User chose decision index: 0: '...'\"\n",
    "                        decision_index = int(decision_index_str)\n",
    "                        chosen_option = decision_point['options'][decision_index]\n",
    "                        \n",
    "                        doc.add_paragraph(f\"Decision {decision_counter}:\", style='List Bullet')\n",
    "                        p = doc.add_paragraph()\n",
    "                        p.add_run(\"Scenario: \").bold = True\n",
    "                        p.add_run(decision_point['question'])\n",
    "\n",
    "                        p = doc.add_paragraph()\n",
    "                        p.add_run(\"Participant's Choice: \").bold = True\n",
    "                        p.add_run(chosen_option['text'])\n",
    "                        \n",
    "                        kc_impact_str = \", \".join([f\"{imp['score']} to {imp['kc_identifier']}\" for imp in chosen_option.get('kc_impacts', [])])\n",
    "                        p = doc.add_paragraph()\n",
    "                        p.add_run(\"Immediate KC Impact: \").bold = True\n",
    "                        p.add_run(kc_impact_str if kc_impact_str else \"None\")\n",
    "                        \n",
    "                        doc.add_paragraph() # Add some space\n",
    "                        decision_counter += 1\n",
    "\n",
    "    except (json.JSONDecodeError, KeyError, IndexError, TypeError, ValueError) as e:\n",
    "        doc.add_paragraph(f\"Error parsing decision path: {e}\")\n",
    "\n",
    "def generate_report_for_user(user_name, conn, lookup_tables):\n",
    "    \"\"\"Main function to generate a single report for a given user.\"\"\"\n",
    "    print(f\"\\n--- Generating report for {user_name} ---\")\n",
    "    \n",
    "    # 1. Fetch all data for this specific user\n",
    "    user_info = pd.read_sql(\"SELECT id FROM users WHERE name = %(name)s\", conn, params={\"name\": user_name})\n",
    "    if user_info.empty:\n",
    "        print(f\"User '{user_name}' not found in the database. Skipping.\")\n",
    "        return\n",
    "    user_id = user_info['id'].iloc[0]\n",
    "    \n",
    "    df_user_goals = pd.read_sql(\"SELECT * FROM user_goals WHERE user_id = %(user_id)s ORDER BY goal_id\", conn, params={\"user_id\": str(user_id)})\n",
    "    df_metric_history = pd.read_sql(\"SELECT * FROM user_metric_history WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
    "    df_kc_scores = pd.read_sql(\"SELECT * FROM user_kc_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
    "    df_metric_scores = pd.read_sql(\"SELECT * FROM user_metric_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
    "    df_goal_kcs = pd.read_sql(\"SELECT * FROM goal_kcs\", conn)\n",
    "    \n",
    "    # <<< FIX: Convert score columns to numeric types right after fetching data\n",
    "    df_kc_scores['current_score'] = pd.to_numeric(df_kc_scores['current_score'], errors='coerce')\n",
    "    df_kc_scores.dropna(subset=['current_score'], inplace=True)\n",
    "    \n",
    "    df_metric_scores['current_value'] = pd.to_numeric(df_metric_scores['current_value'], errors='coerce')\n",
    "    df_metric_scores.dropna(subset=['current_value'], inplace=True)\n",
    "\n",
    "    # 2. Start creating the Word Document\n",
    "    doc = Document()\n",
    "    doc.add_heading('AI Entrepreneurship Game: Learning Report', 0)\n",
    "    doc.add_heading(f\"Participant: {user_name}\", level=1)\n",
    "    doc.add_paragraph(f\"Participant ID: {user_id}\")\n",
    "    \n",
    "    # 3. Section 1: Executive Summary\n",
    "    doc.add_heading(\"1. Executive Summary & Overall Performance\", level=2)\n",
    "    \n",
    "    # Final Metrics\n",
    "    doc.add_paragraph().add_run(\"Final Key Metrics:\").bold = True\n",
    "    if df_metric_scores.empty:\n",
    "        doc.add_paragraph(\"No final metric scores available.\", style='List Bullet')\n",
    "    else:\n",
    "        for _, row in df_metric_scores.iterrows():\n",
    "            metric_name = lookup_tables['metrics'].get(row['metric_id'], {}).get('name', f'Metric {row[\"metric_id\"]}')\n",
    "            doc.add_paragraph(f\"{metric_name}: {row['current_value']:.2f}\", style='List Bullet')\n",
    "        \n",
    "    # KC Strengths/Weaknesses\n",
    "    df_kc_scores_named = df_kc_scores.copy()\n",
    "    df_kc_scores_named['kc_name'] = df_kc_scores_named['kc_id'].apply(lambda x: lookup_tables['kcs'].get(x, {}).get('name', f'KC {x}'))\n",
    "    \n",
    "    doc.add_paragraph().add_run(\"Key Strengths (Top KCs):\").bold = True\n",
    "    if df_kc_scores_named.empty:\n",
    "        doc.add_paragraph(\"No KC scores available.\", style='List Bullet')\n",
    "    else:\n",
    "        for _, row in df_kc_scores_named.nlargest(3, 'current_score').iterrows():\n",
    "            doc.add_paragraph(f\"{row['kc_name']} - Score: {row['current_score']}\", style='List Bullet')\n",
    "\n",
    "    doc.add_paragraph().add_run(\"Areas for Improvement (Lowest KCs):\").bold = True\n",
    "    if df_kc_scores_named.empty:\n",
    "        doc.add_paragraph(\"No KC scores available.\", style='List Bullet')\n",
    "    else:\n",
    "        for _, row in df_kc_scores_named.nsmallest(3, 'current_score').iterrows():\n",
    "            doc.add_paragraph(f\"{row['kc_name']} - Score: {row['current_score']}\", style='List Bullet')\n",
    "        \n",
    "    # 4. Section 2: Goal-by-Goal Analysis\n",
    "    doc.add_heading(\"2. Detailed Goal-by-Goal Analysis\", level=2)\n",
    "\n",
    "    if df_user_goals.empty:\n",
    "        doc.add_paragraph(\"This participant has not attempted any goals yet.\")\n",
    "    else:\n",
    "        for _, goal_row in df_user_goals.iterrows():\n",
    "            goal_id = goal_row['goal_id']\n",
    "            goal_name = lookup_tables['goals'].get(goal_id, {}).get('name', f'Goal {goal_id}')\n",
    "            \n",
    "            doc.add_heading(f\"Goal: {goal_name}\", level=3)\n",
    "            doc.add_paragraph(f\"Status: {goal_row['status']}, Attempts: {goal_row['attempts_for_current_goal_cycle']}\")\n",
    "            \n",
    "            # A. Metric Performance Curve\n",
    "            doc.add_heading(\"A. Metric Performance Curve\", level=4)\n",
    "            df_goal_metrics = df_metric_history[df_metric_history['goal_id'] == goal_id]\n",
    "            metric_plot_img = create_metric_plot(df_goal_metrics, lookup_tables)\n",
    "            if metric_plot_img:\n",
    "                doc.add_picture(metric_plot_img, width=Inches(6.0))\n",
    "            else:\n",
    "                doc.add_paragraph(\"No metric history recorded for this goal.\")\n",
    "\n",
    "            # B. KC Learning Curve\n",
    "            doc.add_heading(\"B. Knowledge Component (KC) Learning Curve\", level=4)\n",
    "            target_kcs_for_goal = df_goal_kcs[df_goal_kcs['goal_id'] == goal_id]['kc_id'].tolist()\n",
    "            kc_plot_img, message = parse_and_plot_kcs(goal_row['dialogue_history'], target_kcs_for_goal, lookup_tables)\n",
    "            if kc_plot_img:\n",
    "                doc.add_picture(kc_plot_img, width=Inches(6.0))\n",
    "            else:\n",
    "                doc.add_paragraph(message)\n",
    "                \n",
    "            # C. Decision Path\n",
    "            add_decision_path_to_doc(doc, goal_row['dialogue_history'], lookup_tables)\n",
    "\n",
    "    # 5. Section 3: Final Entrepreneurial Profile (Simplified logic)\n",
    "    doc.add_heading(\"3. Final Entrepreneurial Profile\", level=2)\n",
    "    \n",
    "    playstyle = \"Balanced Entrepreneur\"\n",
    "    if not df_kc_scores_named.empty:\n",
    "        top_kc = df_kc_scores_named.nlargest(1, 'current_score')\n",
    "        if not top_kc.empty:\n",
    "            top_kc_name = top_kc['kc_name'].iloc[0]\n",
    "            if any(style in top_kc_name for style in ['Trust', 'Reputation', 'Ethical']):\n",
    "                playstyle = \"The Community Builder\"\n",
    "            elif any(style in top_kc_name for style in ['Revenue', 'Pricing', 'profit']):\n",
    "                playstyle = \"The Profit Maximizer\"\n",
    "            \n",
    "    doc.add_paragraph().add_run(\"Identified Playstyle: \").bold = True\n",
    "    doc.add_paragraph(playstyle)\n",
    "    doc.add_paragraph().add_run(\"Recommendations:\").bold = True\n",
    "    doc.add_paragraph(\"Based on the KC scores, this participant could benefit from focusing on scenarios that challenge their lower-scoring skills to develop a more well-rounded entrepreneurial profile.\")\n",
    "\n",
    "    # 6. Save the document\n",
    "    file_name = f\"Learning_Report_{user_name}.docx\"\n",
    "    doc.save(file_name)\n",
    "    print(f\"Successfully generated report: {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching lookup data (KCs, Goals, Metrics)...\n",
      "\n",
      "--- Generating report for P1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  kcs = pd.read_sql(\"SELECT id, kc_identifier, name FROM kcs\", conn).set_index('id').to_dict('index')\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  goals = pd.read_sql(\"SELECT id, name, description FROM goals\", conn).set_index('id').to_dict('index')\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  metrics = pd.read_sql(\"SELECT id, name FROM metrics\", conn).set_index('id').to_dict('index')\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:174: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  user_info = pd.read_sql(\"SELECT id FROM users WHERE name = %(name)s\", conn, params={\"name\": user_name})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:180: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_user_goals = pd.read_sql(\"SELECT * FROM user_goals WHERE user_id = %(user_id)s ORDER BY goal_id\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:181: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_history = pd.read_sql(\"SELECT * FROM user_metric_history WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:182: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_kc_scores = pd.read_sql(\"SELECT * FROM user_kc_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:183: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_scores = pd.read_sql(\"SELECT * FROM user_metric_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:184: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_goal_kcs = pd.read_sql(\"SELECT * FROM goal_kcs\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated report: Learning_Report_P1.docx\n",
      "\n",
      "--- Generating report for P2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:174: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  user_info = pd.read_sql(\"SELECT id FROM users WHERE name = %(name)s\", conn, params={\"name\": user_name})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:180: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_user_goals = pd.read_sql(\"SELECT * FROM user_goals WHERE user_id = %(user_id)s ORDER BY goal_id\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:181: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_history = pd.read_sql(\"SELECT * FROM user_metric_history WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:182: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_kc_scores = pd.read_sql(\"SELECT * FROM user_kc_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:183: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_scores = pd.read_sql(\"SELECT * FROM user_metric_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:184: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_goal_kcs = pd.read_sql(\"SELECT * FROM goal_kcs\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated report: Learning_Report_P2.docx\n",
      "\n",
      "--- Generating report for P3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:174: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  user_info = pd.read_sql(\"SELECT id FROM users WHERE name = %(name)s\", conn, params={\"name\": user_name})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:180: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_user_goals = pd.read_sql(\"SELECT * FROM user_goals WHERE user_id = %(user_id)s ORDER BY goal_id\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:181: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_history = pd.read_sql(\"SELECT * FROM user_metric_history WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:182: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_kc_scores = pd.read_sql(\"SELECT * FROM user_kc_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:183: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_scores = pd.read_sql(\"SELECT * FROM user_metric_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:184: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_goal_kcs = pd.read_sql(\"SELECT * FROM goal_kcs\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated report: Learning_Report_P3.docx\n",
      "\n",
      "--- Generating report for P4 ---\n",
      "Successfully generated report: Learning_Report_P4.docx\n",
      "\n",
      "--- Generating report for P5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:174: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  user_info = pd.read_sql(\"SELECT id FROM users WHERE name = %(name)s\", conn, params={\"name\": user_name})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:180: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_user_goals = pd.read_sql(\"SELECT * FROM user_goals WHERE user_id = %(user_id)s ORDER BY goal_id\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:181: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_history = pd.read_sql(\"SELECT * FROM user_metric_history WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:182: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_kc_scores = pd.read_sql(\"SELECT * FROM user_kc_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:183: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_scores = pd.read_sql(\"SELECT * FROM user_metric_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:184: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_goal_kcs = pd.read_sql(\"SELECT * FROM goal_kcs\", conn)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:174: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  user_info = pd.read_sql(\"SELECT id FROM users WHERE name = %(name)s\", conn, params={\"name\": user_name})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:180: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_user_goals = pd.read_sql(\"SELECT * FROM user_goals WHERE user_id = %(user_id)s ORDER BY goal_id\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:181: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_history = pd.read_sql(\"SELECT * FROM user_metric_history WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:182: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_kc_scores = pd.read_sql(\"SELECT * FROM user_kc_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:183: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_scores = pd.read_sql(\"SELECT * FROM user_metric_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:184: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_goal_kcs = pd.read_sql(\"SELECT * FROM goal_kcs\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated report: Learning_Report_P5.docx\n",
      "\n",
      "--- Generating report for P6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:174: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  user_info = pd.read_sql(\"SELECT id FROM users WHERE name = %(name)s\", conn, params={\"name\": user_name})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:180: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_user_goals = pd.read_sql(\"SELECT * FROM user_goals WHERE user_id = %(user_id)s ORDER BY goal_id\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:181: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_history = pd.read_sql(\"SELECT * FROM user_metric_history WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:182: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_kc_scores = pd.read_sql(\"SELECT * FROM user_kc_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:183: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_scores = pd.read_sql(\"SELECT * FROM user_metric_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:184: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_goal_kcs = pd.read_sql(\"SELECT * FROM goal_kcs\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated report: Learning_Report_P6.docx\n",
      "\n",
      "--- Generating report for P7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:174: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  user_info = pd.read_sql(\"SELECT id FROM users WHERE name = %(name)s\", conn, params={\"name\": user_name})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:180: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_user_goals = pd.read_sql(\"SELECT * FROM user_goals WHERE user_id = %(user_id)s ORDER BY goal_id\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:181: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_history = pd.read_sql(\"SELECT * FROM user_metric_history WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:182: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_kc_scores = pd.read_sql(\"SELECT * FROM user_kc_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:183: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_scores = pd.read_sql(\"SELECT * FROM user_metric_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:184: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_goal_kcs = pd.read_sql(\"SELECT * FROM goal_kcs\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated report: Learning_Report_P7.docx\n",
      "\n",
      "--- Generating report for P8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:174: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  user_info = pd.read_sql(\"SELECT id FROM users WHERE name = %(name)s\", conn, params={\"name\": user_name})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:180: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_user_goals = pd.read_sql(\"SELECT * FROM user_goals WHERE user_id = %(user_id)s ORDER BY goal_id\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:181: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_history = pd.read_sql(\"SELECT * FROM user_metric_history WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:182: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_kc_scores = pd.read_sql(\"SELECT * FROM user_kc_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:183: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_scores = pd.read_sql(\"SELECT * FROM user_metric_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:184: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_goal_kcs = pd.read_sql(\"SELECT * FROM goal_kcs\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated report: Learning_Report_P8.docx\n",
      "\n",
      "--- Generating report for P9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:174: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  user_info = pd.read_sql(\"SELECT id FROM users WHERE name = %(name)s\", conn, params={\"name\": user_name})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:180: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_user_goals = pd.read_sql(\"SELECT * FROM user_goals WHERE user_id = %(user_id)s ORDER BY goal_id\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:181: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_history = pd.read_sql(\"SELECT * FROM user_metric_history WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:182: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_kc_scores = pd.read_sql(\"SELECT * FROM user_kc_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:183: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_scores = pd.read_sql(\"SELECT * FROM user_metric_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:184: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_goal_kcs = pd.read_sql(\"SELECT * FROM goal_kcs\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated report: Learning_Report_P9.docx\n",
      "\n",
      "--- Generating report for P10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:174: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  user_info = pd.read_sql(\"SELECT id FROM users WHERE name = %(name)s\", conn, params={\"name\": user_name})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:180: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_user_goals = pd.read_sql(\"SELECT * FROM user_goals WHERE user_id = %(user_id)s ORDER BY goal_id\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:181: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_history = pd.read_sql(\"SELECT * FROM user_metric_history WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:182: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_kc_scores = pd.read_sql(\"SELECT * FROM user_kc_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:183: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_metric_scores = pd.read_sql(\"SELECT * FROM user_metric_scores WHERE user_id = %(user_id)s\", conn, params={\"user_id\": str(user_id)})\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_10632\\1756634312.py:184: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_goal_kcs = pd.read_sql(\"SELECT * FROM goal_kcs\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated report: Learning_Report_P10.docx\n",
      "\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    conn = get_db_connection()\n",
    "    if conn:\n",
    "        try:\n",
    "            lookup_data = fetch_lookup_data(conn)\n",
    "            for name in PARTICIPANT_NAMES:\n",
    "                generate_report_for_user(name, conn, lookup_data)\n",
    "        finally:\n",
    "            conn.close()\n",
    "            print(\"\\nDatabase connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from CSV files...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- Generating report for P9 ---\n",
      "Warning: Could not parse dialogue history. invalid literal for int() with base 10: '\"Increase prices slightly to cover increased costs, ensuring quality service.\"'\n",
      "Successfully generated report: Learning_Report_P9.docx\n",
      "\n",
      "--- Generating report for P8 ---\n",
      "Warning: Could not parse dialogue history. invalid literal for int() with base 10: '\"Lower prices to attract more customers and increase market share.\"'\n",
      "Successfully generated report: Learning_Report_P8.docx\n",
      "\n",
      "--- Generating report for P7 ---\n",
      "Warning: Could not parse dialogue history. invalid literal for int() with base 10: '\"Conduct a thorough analysis of competitor pricing and adjust accordingly.\"'\n",
      "Successfully generated report: Learning_Report_P7.docx\n",
      "\n",
      "--- Generating report for P6 ---\n",
      "Warning: Could not parse dialogue history. invalid literal for int() with base 10: '\"Introduce a loyalty program to reward repeat customers and boost satisfaction.\"'\n",
      "Successfully generated report: Learning_Report_P6.docx\n",
      "\n",
      "--- Generating report for P5 ---\n",
      "Successfully generated report: Learning_Report_P5.docx\n",
      "\n",
      "--- Generating report for P4 ---\n",
      "Successfully generated report: Learning_Report_P4.docx\n",
      "\n",
      "--- Generating report for P3 ---\n",
      "Successfully generated report: Learning_Report_P3.docx\n",
      "\n",
      "--- Generating report for P2 ---\n",
      "Successfully generated report: Learning_Report_P2.docx\n",
      "\n",
      "--- Generating report for P10 ---\n",
      "Warning: Could not parse dialogue history. invalid literal for int() with base 10: '\"Conduct a detailed cost analysis to identify areas to optimize.\"'\n",
      "Successfully generated report: Learning_Report_P10.docx\n",
      "\n",
      "--- Generating report for P1 ---\n",
      "Successfully generated report: Learning_Report_P1.docx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "import json\n",
    "\n",
    "# --- Configuration & Business Logic ---\n",
    "\n",
    "# This dictionary encodes the logic from your route.ts file\n",
    "METRIC_WEIGHTS = {\n",
    "    \"Revenue\": 450,\n",
    "    \"Customer Satisfaction\": 2,\n",
    "    \"Reputation\": 0.15,\n",
    "    \"Ethical Decision Making\": 2,\n",
    "    \"Risk-Taking\": 2,\n",
    "    \"default\": 2\n",
    "}\n",
    "\n",
    "PARTICIPANT_NAMES = [f'P{i}' for i in range(1, 11)]\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Loads all necessary CSV files into pandas DataFrames.\"\"\"\n",
    "    print(\"Loading data from CSV files...\")\n",
    "    try:\n",
    "        data = {\n",
    "            'users': pd.read_csv('users_rows.csv'),\n",
    "            'user_goals': pd.read_csv('user_goals_rows.csv'),\n",
    "            'user_kc_scores': pd.read_csv('user_kc_scores_rows.csv'),\n",
    "            'user_metric_scores': pd.read_csv('user_metric_scores_rows.csv'),\n",
    "            'kcs': pd.read_csv('kcs_rows.csv'),\n",
    "            'metrics': pd.read_csv('metrics_rows.csv'),\n",
    "            'goals': pd.read_csv('goals_rows.csv'),\n",
    "            'kc_metric_effects': pd.read_csv('kc_metric_effects_rows.csv')\n",
    "        }\n",
    "        print(\"Data loaded successfully.\")\n",
    "        return data\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find a required CSV file. {e}\")\n",
    "        return None\n",
    "\n",
    "def calculate_peer_averages(df_metric_scores, df_kc_scores):\n",
    "    \"\"\"Calculates the average scores across all participants.\"\"\"\n",
    "    avg_metrics = df_metric_scores.groupby('metric_id')['current_value'].mean()\n",
    "    avg_kcs = df_kc_scores.groupby('kc_id')['current_score'].mean()\n",
    "    return avg_metrics, avg_kcs\n",
    "\n",
    "def get_metric_change(kc_id, score_change, data_tables):\n",
    "    \"\"\"Calculates the metric changes for a given KC score change based on business logic.\"\"\"\n",
    "    metric_changes = []\n",
    "    # Find which metrics this KC affects\n",
    "    affected_links = data_tables['kc_metric_effects'][data_tables['kc_metric_effects']['kc_id'] == kc_id]\n",
    "    \n",
    "    for _, link in affected_links.iterrows():\n",
    "        metric_id = link['metric_id']\n",
    "        metric_info = data_tables['metrics'].set_index('id').loc[metric_id]\n",
    "        metric_name = metric_info['name']\n",
    "        \n",
    "        weight = METRIC_WEIGHTS.get(metric_name, METRIC_WEIGHTS['default'])\n",
    "        change = score_change * weight\n",
    "        metric_changes.append({'metric_name': metric_name, 'change': change})\n",
    "        \n",
    "    return metric_changes\n",
    "\n",
    "def parse_final_attempt(dialogue_history_json, data_tables):\n",
    "    \"\"\"Parses the dialogue history for the final attempt to get KC and metric changes.\"\"\"\n",
    "    kc_changes_by_decision = {}\n",
    "    \n",
    "    if not isinstance(dialogue_history_json, str):\n",
    "        return kc_changes_by_decision\n",
    "\n",
    "    try:\n",
    "        history = json.loads(dialogue_history_json)\n",
    "        decision_counter = 0\n",
    "        for i, turn in enumerate(history):\n",
    "            if turn.get('role') == 'user' and 'User chose decision index' in turn.get('content', ''):\n",
    "                decision_counter += 1\n",
    "                assistant_turn = history[i-1]\n",
    "                assistant_content = json.loads(assistant_turn['content'])\n",
    "                decision_point = assistant_content.get('decisionPoint', {})\n",
    "                \n",
    "                decision_index_str = turn['content'].split(': ')[-1].split(':')[0].strip()\n",
    "                decision_index = int(decision_index_str)\n",
    "                chosen_option = decision_point.get('options', [])[decision_index]\n",
    "\n",
    "                impacts = []\n",
    "                for impact in chosen_option.get('kc_impacts', []):\n",
    "                    kc_identifier = impact['kc_identifier']\n",
    "                    score_change = impact.get('score', 0)\n",
    "                    \n",
    "                    # Find kc_id and kc_name\n",
    "                    kc_row = data_tables['kcs'][data_tables['kcs']['kc_identifier'] == kc_identifier]\n",
    "                    if not kc_row.empty:\n",
    "                        kc_id = kc_row.iloc[0]['id']\n",
    "                        kc_name = kc_row.iloc[0]['name']\n",
    "                        metric_deltas = get_metric_change(kc_id, score_change, data_tables)\n",
    "                        impacts.append({\n",
    "                            'kc_id': kc_id,\n",
    "                            'kc_name': kc_name,\n",
    "                            'score_change': score_change,\n",
    "                            'metric_impacts': metric_deltas\n",
    "                        })\n",
    "                kc_changes_by_decision[decision_counter] = impacts\n",
    "    except (json.JSONDecodeError, KeyError, IndexError, TypeError, ValueError) as e:\n",
    "        print(f\"Warning: Could not parse dialogue history. {e}\")\n",
    "\n",
    "    return kc_changes_by_decision\n",
    "\n",
    "def generate_report_for_user(user_info, data, peer_averages):\n",
    "    \"\"\"Generates a single DOCX report for a given user.\"\"\"\n",
    "    user_id = user_info['id']\n",
    "    user_name = user_info['name']\n",
    "    \n",
    "    print(f\"\\n--- Generating report for {user_name} ---\")\n",
    "\n",
    "    # Filter data for the current user\n",
    "    user_goals = data['user_goals'][data['user_goals']['user_id'] == user_id]\n",
    "    user_kc_scores = data['user_kc_scores'][data['user_kc_scores']['user_id'] == user_id]\n",
    "    user_metric_scores = data['user_metric_scores'][data['user_metric_scores']['user_id'] == user_id]\n",
    "\n",
    "    doc = Document()\n",
    "    doc.add_heading('AI Entrepreneurship Game: Learning Report', 0)\n",
    "    doc.add_heading(f\"Participant: {user_name}\", level=1)\n",
    "    \n",
    "    # --- Section 1: Executive Summary ---\n",
    "    doc.add_heading(\"1. Executive Summary & Overall Performance\", level=2)\n",
    "    doc.add_paragraph().add_run(\"Final Key Metrics (vs. Peer Average):\").bold = True\n",
    "    \n",
    "    for _, row in user_metric_scores.iterrows():\n",
    "        metric_id = row['metric_id']\n",
    "        metric_name = data['metrics'].set_index('id').loc[metric_id, 'name']\n",
    "        peer_avg = peer_averages['metrics'].get(metric_id, 0)\n",
    "        doc.add_paragraph(f\"{metric_name}: {row['current_value']:.2f} (Peer Avg: {peer_avg:.2f})\", style='List Bullet')\n",
    "\n",
    "    doc.add_paragraph().add_run(\"Key Strengths (Top KCs):\").bold = True\n",
    "    for _, row in user_kc_scores.nlargest(3, 'current_score').iterrows():\n",
    "        kc_name = data['kcs'].set_index('id').loc[row['kc_id'], 'name']\n",
    "        doc.add_paragraph(f\"{kc_name} - Final Score: {row['current_score']}\", style='List Bullet')\n",
    "        \n",
    "    doc.add_paragraph().add_run(\"Areas for Improvement (Lowest KCs):\").bold = True\n",
    "    for _, row in user_kc_scores.nsmallest(3, 'current_score').iterrows():\n",
    "        kc_name = data['kcs'].set_index('id').loc[row['kc_id'], 'name']\n",
    "        doc.add_paragraph(f\"{kc_name} - Final Score: {row['current_score']}\", style='List Bullet')\n",
    "        \n",
    "    # --- Section 2: Reconstructed Decision Analysis ---\n",
    "    doc.add_heading(\"2. Decision & KC Impact Analysis\", level=2)\n",
    "\n",
    "    for _, goal_row in user_goals.iterrows():\n",
    "        goal_id = goal_row['goal_id']\n",
    "        goal_name = data['goals'].set_index('id').loc[goal_id, 'name']\n",
    "        \n",
    "        doc.add_heading(f\"Goal: {goal_name}\", level=3)\n",
    "        doc.add_paragraph(f\"Status: {goal_row['status']}, Attempts: {goal_row['attempts_for_current_goal_cycle']}\")\n",
    "        \n",
    "        # Step 1: Analyze the final, known attempt\n",
    "        final_attempt_impacts = parse_final_attempt(goal_row['dialogue_history'], data)\n",
    "        \n",
    "        # Sum up changes from the final attempt\n",
    "        final_attempt_kc_delta = pd.Series(dtype=float)\n",
    "        for _, impacts in final_attempt_impacts.items():\n",
    "            for impact in impacts:\n",
    "                final_attempt_kc_delta[impact['kc_id']] = final_attempt_kc_delta.get(impact['kc_id'], 0) + impact['score_change']\n",
    "        \n",
    "        # Step 2: Calculate the total change needed in the missing attempts\n",
    "        kc_scores_for_goal = user_kc_scores[user_kc_scores['kc_id'].isin(final_attempt_kc_delta.index)]\n",
    "        kc_delta_for_missing_attempts = pd.Series(dtype=float)\n",
    "        for _, kc_row in kc_scores_for_goal.iterrows():\n",
    "            kc_id = kc_row['kc_id']\n",
    "            final_score = kc_row['current_score']\n",
    "            change_from_last_attempt = final_attempt_kc_delta.get(kc_id, 0)\n",
    "            kc_delta_for_missing_attempts[kc_id] = final_score - change_from_last_attempt\n",
    "\n",
    "        # Step 3: Reconstruct and combine with known data\n",
    "        num_attempts = goal_row['attempts_for_current_goal_cycle']\n",
    "        num_decisions_per_attempt = 3\n",
    "        num_missing_decisions = (num_attempts - 1) * num_decisions_per_attempt\n",
    "        \n",
    "        table = doc.add_table(rows=1, cols=4)\n",
    "        table.style = 'Table Grid'\n",
    "        hdr_cells = table.rows[0].cells\n",
    "        hdr_cells[0].text = 'Decision #'\n",
    "        hdr_cells[1].text = 'KC Impacted'\n",
    "        hdr_cells[2].text = 'KC Score Change'\n",
    "        hdr_cells[3].text = 'Metric Change'\n",
    "\n",
    "        # Reconstruct missing decisions\n",
    "        if num_missing_decisions > 0:\n",
    "            for decision_num in range(1, num_missing_decisions + 1):\n",
    "                for kc_id, total_change in kc_delta_for_missing_attempts.items():\n",
    "                    kc_name = data['kcs'].set_index('id').loc[kc_id, 'name']\n",
    "                    # Distribute the change evenly\n",
    "                    score_change_per_step = total_change / num_missing_decisions\n",
    "                    metric_changes = get_metric_change(kc_id, score_change_per_step, data)\n",
    "                    \n",
    "                    row_cells = table.add_row().cells\n",
    "                    row_cells[0].text = f\"{decision_num}\"\n",
    "                    row_cells[1].text = kc_name\n",
    "                    row_cells[2].text = f\"{score_change_per_step:+.2f}\"\n",
    "                    row_cells[3].text = \"\\n\".join([f\"{mc['change']:+.2f} {mc['metric_name']}\" for mc in metric_changes])\n",
    "\n",
    "        # Add known decisions from final attempt\n",
    "        start_decision = num_missing_decisions + 1\n",
    "        for i, impacts in final_attempt_impacts.items():\n",
    "            decision_num = start_decision + i -1\n",
    "            if not impacts:\n",
    "                row_cells = table.add_row().cells\n",
    "                row_cells[0].text = str(decision_num)\n",
    "                row_cells[1].text = \"No KC Impact\"\n",
    "            for impact in impacts:\n",
    "                row_cells = table.add_row().cells\n",
    "                row_cells[0].text = str(decision_num)\n",
    "                row_cells[1].text = impact['kc_name']\n",
    "                row_cells[2].text = f\"{impact['score_change']:+.2f}\"\n",
    "                row_cells[3].text = \"\\n\".join([f\"{mc['change']:+.2f} {mc['metric_name']}\" for mc in impact['metric_impacts']])\n",
    "    \n",
    "    # Save the document\n",
    "    file_name = f\"Learning_Report_{user_name}.docx\"\n",
    "    doc.save(file_name)\n",
    "    print(f\"Successfully generated report: {file_name}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_data = load_data()\n",
    "    if all_data:\n",
    "        # Pre-process data types\n",
    "        all_data['user_kc_scores']['current_score'] = pd.to_numeric(all_data['user_kc_scores']['current_score'])\n",
    "        all_data['user_metric_scores']['current_value'] = pd.to_numeric(all_data['user_metric_scores']['current_value'])\n",
    "        \n",
    "        peer_avg_metrics, peer_avg_kcs = calculate_peer_averages(all_data['user_metric_scores'], all_data['user_kc_scores'])\n",
    "        \n",
    "        # Create a user map from name to ID\n",
    "        user_map = all_data['users'][all_data['users']['name'].isin(PARTICIPANT_NAMES)]\n",
    "        \n",
    "        for _, user_row in user_map.iterrows():\n",
    "            generate_report_for_user(user_row, all_data, {'metrics': peer_avg_metrics, 'kcs': peer_avg_kcs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from CSV files...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- Generating report for P9 ---\n",
      "Successfully generated report: Learning_Report_P9.docx\n",
      "\n",
      "--- Generating report for P8 ---\n",
      "Successfully generated report: Learning_Report_P8.docx\n",
      "\n",
      "--- Generating report for P7 ---\n",
      "Successfully generated report: Learning_Report_P7.docx\n",
      "\n",
      "--- Generating report for P6 ---\n",
      "Successfully generated report: Learning_Report_P6.docx\n",
      "\n",
      "--- Generating report for P5 ---\n",
      "Successfully generated report: Learning_Report_P5.docx\n",
      "\n",
      "--- Generating report for P4 ---\n",
      "Successfully generated report: Learning_Report_P4.docx\n",
      "\n",
      "--- Generating report for P3 ---\n",
      "Successfully generated report: Learning_Report_P3.docx\n",
      "\n",
      "--- Generating report for P2 ---\n",
      "Successfully generated report: Learning_Report_P2.docx\n",
      "\n",
      "--- Generating report for P10 ---\n",
      "Successfully generated report: Learning_Report_P10.docx\n",
      "\n",
      "--- Generating report for P1 ---\n",
      "Successfully generated report: Learning_Report_P1.docx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.shared import Pt, Inches\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "\n",
    "# --- Configuration & Business Logic ---\n",
    "METRIC_WEIGHTS = {\n",
    "    \"Revenue\": 450,\n",
    "    \"Customer Satisfaction\": 2,\n",
    "    \"Reputation\": 0.15,\n",
    "    \"Ethical Decision Making\": 2,\n",
    "    \"Risk-Taking\": 2,\n",
    "    \"default\": 2\n",
    "}\n",
    "PARTICIPANT_NAMES = [f'P{i}' for i in range(1, 11)]\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Loads all necessary CSV files into pandas DataFrames.\"\"\"\n",
    "    print(\"Loading data from CSV files...\")\n",
    "    try:\n",
    "        data = {\n",
    "            'users': pd.read_csv('users_rows.csv'),\n",
    "            'user_goals': pd.read_csv('user_goals_rows.csv'),\n",
    "            'user_kc_scores': pd.read_csv('user_kc_scores_rows.csv'),\n",
    "            'user_metric_scores': pd.read_csv('user_metric_scores_rows.csv'),\n",
    "            'kcs': pd.read_csv('kcs_rows.csv'),\n",
    "            'metrics': pd.read_csv('metrics_rows.csv'),\n",
    "            'goals': pd.read_csv('goals_rows.csv'),\n",
    "            'kc_metric_effects': pd.read_csv('kc_metric_effects_rows.csv')\n",
    "        }\n",
    "        print(\"Data loaded successfully.\")\n",
    "        return data\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find a required CSV file. {e}\")\n",
    "        return None\n",
    "\n",
    "def calculate_peer_stats(df_metric_scores, df_kc_scores, data_tables): # <<< NEW FEATURE\n",
    "    \"\"\"Calculates min, average, and max scores across all participants.\"\"\"\n",
    "    peer_metrics = df_metric_scores.groupby('metric_id')['current_value'].agg(['min', 'mean', 'max'])\n",
    "    \n",
    "    # Calculate total KC score per user for leaderboard\n",
    "    user_total_kc = df_kc_scores.groupby('user_id')['current_score'].sum().reset_index()\n",
    "    user_total_kc = user_total_kc.merge(data_tables['users'][['id', 'name']], left_on='user_id', right_on='id')\n",
    "    leaderboard = user_total_kc[['name', 'current_score']].sort_values(by='current_score', ascending=False)\n",
    "    \n",
    "    return peer_metrics, leaderboard\n",
    "\n",
    "def get_metric_change(kc_id, score_change, data_tables):\n",
    "    \"\"\"Calculates the metric changes for a given KC score change based on business logic.\"\"\"\n",
    "    metric_changes = []\n",
    "    affected_links = data_tables['kc_metric_effects'][data_tables['kc_metric_effects']['kc_id'] == kc_id]\n",
    "    \n",
    "    for _, link in affected_links.iterrows():\n",
    "        metric_id = link['metric_id']\n",
    "        metric_info = data_tables['metrics'].set_index('id').loc[metric_id]\n",
    "        metric_name = metric_info['name']\n",
    "        \n",
    "        weight = METRIC_WEIGHTS.get(metric_name, METRIC_WEIGHTS['default'])\n",
    "        change = score_change * weight\n",
    "        metric_changes.append({'metric_name': metric_name, 'change': change})\n",
    "        \n",
    "    return metric_changes\n",
    "\n",
    "def parse_final_attempt(dialogue_history_json, data_tables):\n",
    "    \"\"\"Parses the dialogue history for the final attempt to get KC and metric changes.\"\"\"\n",
    "    kc_changes_by_decision = {}\n",
    "    \n",
    "    if not isinstance(dialogue_history_json, str):\n",
    "        return kc_changes_by_decision\n",
    "\n",
    "    try:\n",
    "        history = json.loads(dialogue_history_json)\n",
    "        decision_counter = 0\n",
    "        for i, turn in enumerate(history):\n",
    "            if turn.get('role') == 'user' and 'User chose decision index' in turn.get('content', ''):\n",
    "                decision_counter += 1\n",
    "                assistant_turn = history[i-1]\n",
    "                assistant_content = json.loads(assistant_turn['content'])\n",
    "                decision_point = assistant_content.get('decisionPoint', {})\n",
    "                \n",
    "                # <<< BUG FIX: Make parsing robust to different dialogue formats\n",
    "                content_part = turn['content'].split(': ', 1)[1]\n",
    "                decision_index_str = content_part.split(':')[0].strip()\n",
    "                decision_index = int(decision_index_str)\n",
    "                \n",
    "                chosen_option = decision_point.get('options', [])[decision_index]\n",
    "\n",
    "                impacts = []\n",
    "                for impact in chosen_option.get('kc_impacts', []):\n",
    "                    kc_identifier = impact['kc_identifier']\n",
    "                    score_change = impact.get('score', 0)\n",
    "                    \n",
    "                    kc_row = data_tables['kcs'][data_tables['kcs']['kc_identifier'] == kc_identifier]\n",
    "                    if not kc_row.empty:\n",
    "                        kc_id = kc_row.iloc[0]['id']\n",
    "                        kc_name = kc_row.iloc[0]['name']\n",
    "                        metric_deltas = get_metric_change(kc_id, score_change, data_tables)\n",
    "                        impacts.append({\n",
    "                            'kc_id': kc_id, 'kc_name': kc_name,\n",
    "                            'score_change': score_change, 'metric_impacts': metric_deltas\n",
    "                        })\n",
    "                kc_changes_by_decision[decision_counter] = impacts\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not parse dialogue history for a goal. Error: {e}\")\n",
    "\n",
    "    return kc_changes_by_decision\n",
    "\n",
    "def create_cumulative_kc_plot(decision_data): # <<< NEW FEATURE\n",
    "    \"\"\"Creates a line chart of cumulative KC scores over decisions.\"\"\"\n",
    "    if not decision_data:\n",
    "        return None\n",
    "        \n",
    "    df = pd.DataFrame(decision_data)\n",
    "    \n",
    "    # Calculate cumulative scores\n",
    "    df['cumulative_score'] = df.groupby('kc_id')['score_change'].cumsum()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    \n",
    "    # Pivot for plotting, using KC ID for shorter labels\n",
    "    pivot_df = df.pivot_table(index='decision_num', columns='kc_id', values='cumulative_score')\n",
    "    pivot_df.plot(kind='line', marker='o', ax=ax)\n",
    "    \n",
    "    ax.set_title(\"Cumulative KC Score Movement per Goal\")\n",
    "    ax.set_xlabel(\"Decision Number\")\n",
    "    ax.set_ylabel(\"Cumulative KC Score\")\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax.legend(title='KC ID')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    img_buffer = BytesIO()\n",
    "    plt.savefig(img_buffer, format='png')\n",
    "    img_buffer.seek(0)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return img_buffer\n",
    "\n",
    "def generate_report_for_user(user_info, data, peer_stats, leaderboard): # <<< NEW FEATURE\n",
    "    \"\"\"Generates a single DOCX report for a given user.\"\"\"\n",
    "    user_id = user_info['id']\n",
    "    user_name = user_info['name']\n",
    "    \n",
    "    print(f\"\\n--- Generating report for {user_name} ---\")\n",
    "\n",
    "    user_goals = data['user_goals'][data['user_goals']['user_id'] == user_id]\n",
    "    user_kc_scores = data['user_kc_scores'][data['user_kc_scores']['user_id'] == user_id]\n",
    "    user_metric_scores = data['user_metric_scores'][data['user_metric_scores']['user_id'] == user_id]\n",
    "\n",
    "    doc = Document()\n",
    "    doc.add_heading('AI Entrepreneurship Game: Learning Report', 0)\n",
    "    doc.add_heading(f\"Participant: {user_name}\", level=1)\n",
    "    \n",
    "    # --- Section 1: Executive Summary ---\n",
    "    doc.add_heading(\"1. Executive Summary & Overall Performance\", level=2)\n",
    "    doc.add_paragraph().add_run(\"Final Key Metrics (vs. Peers):\").bold = True # <<< NEW FEATURE\n",
    "    \n",
    "    for _, row in user_metric_scores.iterrows():\n",
    "        metric_id = row['metric_id']\n",
    "        metric_name = data['metrics'].set_index('id').loc[metric_id, 'name']\n",
    "        if metric_id in peer_stats['metrics'].index:\n",
    "            peer_stat = peer_stats['metrics'].loc[metric_id]\n",
    "            doc.add_paragraph(\n",
    "                f\"{metric_name}: {row['current_value']:.2f} \"\n",
    "                f\"(Peer Min: {peer_stat['min']:.2f}, Avg: {peer_stat['mean']:.2f}, Max: {peer_stat['max']:.2f})\", \n",
    "                style='List Bullet'\n",
    "            )\n",
    "\n",
    "    doc.add_paragraph().add_run(\"Key Strengths (Top KCs):\").bold = True\n",
    "    for _, row in user_kc_scores.nlargest(3, 'current_score').iterrows():\n",
    "        kc_name = data['kcs'].set_index('id').loc[row['kc_id'], 'name']\n",
    "        doc.add_paragraph(f\"{kc_name} - Final Score: {row['current_score']}\", style='List Bullet')\n",
    "        \n",
    "    doc.add_paragraph().add_run(\"Areas for Improvement (Lowest KCs):\").bold = True\n",
    "    for _, row in user_kc_scores.nsmallest(3, 'current_score').iterrows():\n",
    "        kc_name = data['kcs'].set_index('id').loc[row['kc_id'], 'name']\n",
    "        doc.add_paragraph(f\"{kc_name} - Final Score: {row['current_score']}\", style='List Bullet')\n",
    "        \n",
    "    # --- Section 2: Reconstructed Decision Analysis ---\n",
    "    doc.add_heading(\"2. Decision & KC Impact Analysis\", level=2)\n",
    "\n",
    "    for _, goal_row in user_goals.iterrows():\n",
    "        goal_id = goal_row['goal_id']\n",
    "        goal_name = data['goals'].set_index('id').loc[goal_id, 'name']\n",
    "        \n",
    "        doc.add_heading(f\"Goal: {goal_name}\", level=3)\n",
    "        doc.add_paragraph(f\"Status: {goal_row['status']}, Attempts: {goal_row['attempts_for_current_goal_cycle']}\")\n",
    "        \n",
    "        final_attempt_impacts = parse_final_attempt(goal_row['dialogue_history'], data)\n",
    "        final_attempt_kc_delta = pd.Series(dtype=float)\n",
    "        for _, impacts in final_attempt_impacts.items():\n",
    "            for impact in impacts:\n",
    "                final_attempt_kc_delta[impact['kc_id']] = final_attempt_kc_delta.get(impact['kc_id'], 0) + impact['score_change']\n",
    "        \n",
    "        kc_scores_for_goal = user_kc_scores[user_kc_scores['kc_id'].isin(final_attempt_kc_delta.index)]\n",
    "        kc_delta_for_missing_attempts = pd.Series(dtype=float)\n",
    "        for _, kc_row in kc_scores_for_goal.iterrows():\n",
    "            kc_id = kc_row['kc_id']\n",
    "            final_score = kc_row['current_score']\n",
    "            change_from_last_attempt = final_attempt_kc_delta.get(kc_id, 0)\n",
    "            kc_delta_for_missing_attempts[kc_id] = final_score - change_from_last_attempt\n",
    "\n",
    "        num_attempts = goal_row['attempts_for_current_goal_cycle']\n",
    "        if num_attempts == 0: num_attempts = 1 # Handle cases where attempts might be 0\n",
    "        num_decisions_per_attempt = 3\n",
    "        num_missing_decisions = (num_attempts - 1) * num_decisions_per_attempt\n",
    "        \n",
    "        table = doc.add_table(rows=1, cols=4)\n",
    "        table.style = 'Table Grid'\n",
    "        hdr_cells = table.rows[0].cells\n",
    "        hdr_cells[0].text = 'Decision #'\n",
    "        hdr_cells[1].text = 'KC Impacted'\n",
    "        hdr_cells[2].text = 'KC Score Change'\n",
    "        hdr_cells[3].text = 'Metric Change'\n",
    "\n",
    "        all_decision_data = [] # For plotting\n",
    "\n",
    "        # Reconstruct\n",
    "        if num_missing_decisions > 0:\n",
    "            for decision_num in range(1, num_missing_decisions + 1):\n",
    "                for kc_id, total_change in kc_delta_for_missing_attempts.items():\n",
    "                    kc_name = data['kcs'].set_index('id').loc[kc_id, 'name']\n",
    "                    score_change_per_step = total_change / num_missing_decisions if num_missing_decisions > 0 else 0\n",
    "                    all_decision_data.append({'decision_num': decision_num, 'kc_id': kc_id, 'score_change': score_change_per_step})\n",
    "        \n",
    "        # Add known data\n",
    "        start_decision = num_missing_decisions + 1\n",
    "        for i, impacts in sorted(final_attempt_impacts.items()):\n",
    "            decision_num = start_decision + i - 1\n",
    "            for impact in impacts:\n",
    "                all_decision_data.append({'decision_num': decision_num, 'kc_id': impact['kc_id'], 'score_change': impact['score_change']})\n",
    "        \n",
    "        # Populate table from combined data\n",
    "        for item in sorted(all_decision_data, key=lambda x: x['decision_num']):\n",
    "            kc_name = data['kcs'].set_index('id').loc[item['kc_id'], 'name']\n",
    "            metric_changes = get_metric_change(item['kc_id'], item['score_change'], data)\n",
    "            \n",
    "            row_cells = table.add_row().cells\n",
    "            row_cells[0].text = str(item['decision_num'])\n",
    "            row_cells[1].text = kc_name\n",
    "            row_cells[2].text = f\"{item['score_change']:+.2f}\"\n",
    "            row_cells[3].text = \"\\n\".join([f\"{mc['change']:+.2f} {mc['metric_name']}\" for mc in metric_changes])\n",
    "            \n",
    "        # --- Section 2b: Cumulative KC Plot & Legend ---\n",
    "        # <<< NEW FEATURE\n",
    "        kc_plot_img = create_cumulative_kc_plot(all_decision_data)\n",
    "        if kc_plot_img:\n",
    "            doc.add_paragraph() # spacing\n",
    "            doc.add_picture(kc_plot_img, width=Inches(6.0))\n",
    "            \n",
    "            # Add KC Legend Table\n",
    "            doc.add_paragraph(\"KC ID Legend:\")\n",
    "            involved_kcs = pd.DataFrame(all_decision_data)['kc_id'].unique()\n",
    "            legend_table = doc.add_table(rows=1, cols=2)\n",
    "            legend_table.style = 'Table Grid'\n",
    "            legend_table.rows[0].cells[0].text = 'KC ID'\n",
    "            legend_table.rows[0].cells[1].text = 'KC Name'\n",
    "            for kc_id in involved_kcs:\n",
    "                cells = legend_table.add_row().cells\n",
    "                cells[0].text = str(kc_id)\n",
    "                cells[1].text = data['kcs'].set_index('id').loc[kc_id, 'name']\n",
    "        doc.add_paragraph() # spacing\n",
    "\n",
    "    # --- Section 3: Learning Leaderboard ---\n",
    "    # <<< NEW FEATURE\n",
    "    doc.add_heading(\"3. Learning Performance Leaderboard\", level=2)\n",
    "    doc.add_paragraph(\"This ranks participants by their total cumulative score across all Knowledge Components.\")\n",
    "    leaderboard_table = doc.add_table(rows=1, cols=3)\n",
    "    leaderboard_table.style = 'Table Grid'\n",
    "    hdr_cells = leaderboard_table.rows[0].cells\n",
    "    hdr_cells[0].text = 'Rank'\n",
    "    hdr_cells[1].text = 'Participant'\n",
    "    hdr_cells[2].text = 'Total KC Score'\n",
    "    \n",
    "    for i, (_, row) in enumerate(leaderboard.iterrows()):\n",
    "        cells = leaderboard_table.add_row().cells\n",
    "        cells[0].text = str(i + 1)\n",
    "        cells[1].text = row['name']\n",
    "        cells[2].text = f\"{row['current_score']}\"\n",
    "        if row['name'] == user_name: # Highlight the current user\n",
    "            for cell in cells:\n",
    "                for paragraph in cell.paragraphs:\n",
    "                    for run in paragraph.runs:\n",
    "                        run.bold = True\n",
    "    \n",
    "    # Save the document\n",
    "    file_name = f\"Learning_Report_{user_name}.docx\"\n",
    "    doc.save(file_name)\n",
    "    print(f\"Successfully generated report: {file_name}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_data = load_data()\n",
    "    if all_data:\n",
    "        all_data['user_kc_scores']['current_score'] = pd.to_numeric(all_data['user_kc_scores']['current_score'])\n",
    "        all_data['user_metric_scores']['current_value'] = pd.to_numeric(all_data['user_metric_scores']['current_value'])\n",
    "        \n",
    "        peer_stats_metrics, leaderboard_data = calculate_peer_stats(all_data['user_metric_scores'], all_data['user_kc_scores'], all_data)\n",
    "        \n",
    "        user_map = all_data['users'][all_data['users']['name'].isin(PARTICIPANT_NAMES)]\n",
    "        \n",
    "        for _, user_row in user_map.iterrows():\n",
    "            generate_report_for_user(user_row, all_data, {'metrics': peer_stats_metrics}, leaderboard_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from CSV files...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- Generating report for P9 ---\n",
      "Successfully generated report: Learning_Report_P9_alternative.docx\n",
      "\n",
      "--- Generating report for P8 ---\n",
      "Successfully generated report: Learning_Report_P8_alternative.docx\n",
      "\n",
      "--- Generating report for P7 ---\n",
      "Successfully generated report: Learning_Report_P7_alternative.docx\n",
      "\n",
      "--- Generating report for P6 ---\n",
      "Successfully generated report: Learning_Report_P6_alternative.docx\n",
      "\n",
      "--- Generating report for P5 ---\n",
      "Successfully generated report: Learning_Report_P5_alternative.docx\n",
      "\n",
      "--- Generating report for P4 ---\n",
      "Successfully generated report: Learning_Report_P4_alternative.docx\n",
      "\n",
      "--- Generating report for P3 ---\n",
      "Successfully generated report: Learning_Report_P3_alternative.docx\n",
      "\n",
      "--- Generating report for P2 ---\n",
      "Successfully generated report: Learning_Report_P2_alternative.docx\n",
      "\n",
      "--- Generating report for P10 ---\n",
      "Successfully generated report: Learning_Report_P10_alternative.docx\n",
      "\n",
      "--- Generating report for P1 ---\n",
      "Successfully generated report: Learning_Report_P1_alternative.docx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.shared import Pt, Inches\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "\n",
    "# --- Configuration & Business Logic ---\n",
    "METRIC_WEIGHTS = {\n",
    "    \"Revenue\": 450,\n",
    "    \"Customer Satisfaction\": 2,\n",
    "    \"Reputation\": 0.15,\n",
    "    \"Ethical Decision Making\": 2,\n",
    "    \"Risk-Taking\": 2,\n",
    "    \"default\": 2\n",
    "}\n",
    "PARTICIPANT_NAMES = [f'P{i}' for i in range(1, 11)]\n",
    "\n",
    "# <<< NEW FEATURE: Map key metrics to their primary learning component for analysis\n",
    "METRIC_TO_KC_MAP = {\n",
    "    'Revenue': 'KC6',  # KC6 is 'Calculate revenue, costs, and profit'\n",
    "    'Reputation': 'KC5', # KC5 is 'Recognize how trust and reputation grow business'\n",
    "    'Ethical Decision Making': 'KC18' # KC18 is 'Navigate ethical dilemmas'\n",
    "}\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Loads all necessary CSV files into pandas DataFrames.\"\"\"\n",
    "    print(\"Loading data from CSV files...\")\n",
    "    try:\n",
    "        data = {\n",
    "            'users': pd.read_csv('users_rows.csv'),\n",
    "            'user_goals': pd.read_csv('user_goals_rows.csv'),\n",
    "            'user_kc_scores': pd.read_csv('user_kc_scores_rows.csv'),\n",
    "            'user_metric_scores': pd.read_csv('user_metric_scores_rows.csv'),\n",
    "            'kcs': pd.read_csv('kcs_rows.csv'),\n",
    "            'metrics': pd.read_csv('metrics_rows.csv'),\n",
    "            'goals': pd.read_csv('goals_rows.csv'),\n",
    "            'kc_metric_effects': pd.read_csv('kc_metric_effects_rows.csv')\n",
    "        }\n",
    "        print(\"Data loaded successfully.\")\n",
    "        return data\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find a required CSV file. {e}\")\n",
    "        return None\n",
    "\n",
    "def calculate_peer_stats(df_metric_scores, df_kc_scores, data_tables):\n",
    "    \"\"\"Calculates min, average, and max scores across all participants.\"\"\"\n",
    "    peer_metrics = df_metric_scores.groupby('metric_id')['current_value'].agg(['min', 'mean', 'max'])\n",
    "    user_total_kc = df_kc_scores.groupby('user_id')['current_score'].sum().reset_index()\n",
    "    user_total_kc = user_total_kc.merge(data_tables['users'][['id', 'name']], left_on='user_id', right_on='id')\n",
    "    leaderboard = user_total_kc[['name', 'current_score']].sort_values(by='current_score', ascending=False)\n",
    "    return peer_metrics, leaderboard\n",
    "\n",
    "def get_metric_change(kc_id, score_change, data_tables):\n",
    "    \"\"\"Calculates the metric changes for a given KC score change based on business logic.\"\"\"\n",
    "    metric_changes = []\n",
    "    affected_links = data_tables['kc_metric_effects'][data_tables['kc_metric_effects']['kc_id'] == kc_id]\n",
    "    for _, link in affected_links.iterrows():\n",
    "        metric_id = link['metric_id']\n",
    "        metric_info = data_tables['metrics'].set_index('id').loc[metric_id]\n",
    "        metric_name = metric_info['name']\n",
    "        weight = METRIC_WEIGHTS.get(metric_name, METRIC_WEIGHTS['default'])\n",
    "        change = score_change * weight\n",
    "        metric_changes.append({'metric_name': metric_name, 'change': change})\n",
    "    return metric_changes\n",
    "\n",
    "def parse_final_attempt(dialogue_history_json, data_tables):\n",
    "    \"\"\"Parses the dialogue history for the final attempt to get KC and metric changes.\"\"\"\n",
    "    kc_changes_by_decision = {}\n",
    "    if not isinstance(dialogue_history_json, str): return kc_changes_by_decision\n",
    "    try:\n",
    "        history = json.loads(dialogue_history_json)\n",
    "        decision_counter = 0\n",
    "        for i, turn in enumerate(history):\n",
    "            if turn.get('role') == 'user' and 'User chose decision index' in turn.get('content', ''):\n",
    "                decision_counter += 1\n",
    "                assistant_turn = history[i-1]\n",
    "                assistant_content = json.loads(assistant_turn['content'])\n",
    "                decision_point = assistant_content.get('decisionPoint', {})\n",
    "                content_part = turn['content'].split(': ', 1)[1]\n",
    "                decision_index_str = content_part.split(':')[0].strip()\n",
    "                decision_index = int(decision_index_str)\n",
    "                chosen_option = decision_point.get('options', [])[decision_index]\n",
    "                impacts = []\n",
    "                for impact in chosen_option.get('kc_impacts', []):\n",
    "                    kc_identifier = impact['kc_identifier']\n",
    "                    score_change = impact.get('score', 0)\n",
    "                    kc_row = data_tables['kcs'][data_tables['kcs']['kc_identifier'] == kc_identifier]\n",
    "                    if not kc_row.empty:\n",
    "                        kc_id = kc_row.iloc[0]['id']\n",
    "                        kc_name = kc_row.iloc[0]['name']\n",
    "                        metric_deltas = get_metric_change(kc_id, score_change, data_tables)\n",
    "                        impacts.append({'kc_id': kc_id, 'kc_name': kc_name, 'score_change': score_change, 'metric_impacts': metric_deltas})\n",
    "                kc_changes_by_decision[decision_counter] = impacts\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not parse dialogue history for a goal. Error: {e}\")\n",
    "    return kc_changes_by_decision\n",
    "\n",
    "def create_learning_quadrant_plot(decision_data, data_tables): # <<< NEW VISUALIZATION\n",
    "    \"\"\"Creates a Learning Quadrant scatter plot.\"\"\"\n",
    "    if not decision_data: return None\n",
    "    df = pd.DataFrame(decision_data)\n",
    "    \n",
    "    # Calculate initial and final scores for each KC in this goal\n",
    "    kc_summary = df.groupby('kc_id').agg(\n",
    "        score_change=('score_change', 'sum'),\n",
    "        initial_score=('initial_score', 'first')\n",
    "    ).reset_index()\n",
    "    kc_summary['final_score'] = kc_summary['initial_score'] + kc_summary['score_change']\n",
    "    kc_summary['kc_identifier'] = kc_summary['kc_id'].apply(lambda x: data_tables['kcs'].set_index('id').loc[x, 'kc_identifier'])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.scatter(kc_summary['score_change'], kc_summary['final_score'], s=100, alpha=0.7)\n",
    "\n",
    "    # Add labels for each point\n",
    "    for i, row in kc_summary.iterrows():\n",
    "        ax.text(row['score_change'] + 0.1, row['final_score'], row['kc_identifier'], fontsize=9)\n",
    "\n",
    "    # Add quadrant lines and labels\n",
    "    ax.axhline(0, color='grey', lw=0.5)\n",
    "    ax.axvline(0, color='grey', lw=0.5)\n",
    "    ax.set_title('Learning Quadrant for this Goal')\n",
    "    ax.set_xlabel('Growth (KC Score Change during Goal)')\n",
    "    ax.set_ylabel('Competence (Final KC Score after Goal)')\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    # Quadrant labels\n",
    "    xlim = ax.get_xlim(); ylim = ax.get_ylim()\n",
    "    ax.text(xlim[1], ylim[1], ' Masters', ha='right', va='top', alpha=0.5, weight='bold')\n",
    "    ax.text(xlim[0], ylim[1], 'Experts ', ha='left', va='top', alpha=0.5, weight='bold')\n",
    "    ax.text(xlim[0], ylim[0], ' Struggling', ha='left', va='bottom', alpha=0.5, weight='bold')\n",
    "    ax.text(xlim[1], ylim[0], 'Emerging ', ha='right', va='bottom', alpha=0.5, weight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    img_buffer = BytesIO()\n",
    "    plt.savefig(img_buffer, format='png'); img_buffer.seek(0); plt.close(fig)\n",
    "    return img_buffer\n",
    "\n",
    "def create_dual_axis_plot(decision_data, metric_name, data_tables): # <<< NEW VISUALIZATION\n",
    "    \"\"\"Creates a dual-axis plot comparing a metric vs. its relevant KC.\"\"\"\n",
    "    if not decision_data: return None\n",
    "    \n",
    "    # Find the KC identifier for the given metric name\n",
    "    kc_identifier_to_track = METRIC_TO_KC_MAP.get(metric_name)\n",
    "    if not kc_identifier_to_track: return None\n",
    "    \n",
    "    # Find the KC ID for that identifier\n",
    "    kc_id_to_track = data_tables['kcs'][data_tables['kcs']['kc_identifier'] == kc_identifier_to_track]['id'].iloc[0]\n",
    "    \n",
    "    df = pd.DataFrame(decision_data)\n",
    "\n",
    "    # Calculate cumulative metric and KC scores\n",
    "    metric_cumulative = []\n",
    "    kc_cumulative = []\n",
    "    current_metric = 0\n",
    "    current_kc = 0\n",
    "    for i in range(1, 10):\n",
    "        step_data = df[df['decision_num'] == i]\n",
    "        step_metric_change = sum(m['change'] for _, row in step_data.iterrows() for m in get_metric_change(row['kc_id'], row['score_change'], data_tables) if m['metric_name'] == metric_name)\n",
    "        step_kc_change = step_data[step_data['kc_id'] == kc_id_to_track]['score_change'].sum()\n",
    "        current_metric += step_metric_change\n",
    "        current_kc += step_kc_change\n",
    "        metric_cumulative.append(current_metric)\n",
    "        kc_cumulative.append(current_kc)\n",
    "        \n",
    "    fig, ax1 = plt.subplots(figsize=(8, 4))\n",
    "    \n",
    "    # Plot Metric\n",
    "    ax1.plot(range(1, 10), metric_cumulative, 'b-', marker='o', label=f'{metric_name} Change')\n",
    "    ax1.set_xlabel('Decision Number')\n",
    "    ax1.set_ylabel(f'Cumulative {metric_name} Change', color='b')\n",
    "    ax1.tick_params('y', colors='b')\n",
    "    \n",
    "    # Create second y-axis\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(range(1, 10), kc_cumulative, 'r-', marker='s', label=f'{kc_identifier_to_track} Score Change')\n",
    "    ax2.set_ylabel(f'Cumulative {kc_identifier_to_track} Score Change', color='r')\n",
    "    ax2.tick_params('y', colors='r')\n",
    "    \n",
    "    ax1.set_title(f'Performance ({metric_name}) vs. Learning ({kc_identifier_to_track})')\n",
    "    fig.tight_layout()\n",
    "    img_buffer = BytesIO(); plt.savefig(img_buffer, format='png'); img_buffer.seek(0); plt.close(fig)\n",
    "    return img_buffer\n",
    "\n",
    "\n",
    "def generate_report_for_user(user_info, data, peer_stats, leaderboard):\n",
    "    \"\"\"Main report generation function.\"\"\"\n",
    "    user_id = user_info['id']; user_name = user_info['name']\n",
    "    print(f\"\\n--- Generating report for {user_name} ---\")\n",
    "\n",
    "    user_goals = data['user_goals'][data['user_goals']['user_id'] == user_id]\n",
    "    user_kc_scores = data['user_kc_scores'][data['user_kc_scores']['user_id'] == user_id]\n",
    "    user_metric_scores = data['user_metric_scores'][data['user_metric_scores']['user_id'] == user_id]\n",
    "\n",
    "    doc = Document()\n",
    "    doc.add_heading('AI Entrepreneurship Game: Learning Report', 0)\n",
    "    doc.add_heading(f\"Participant: {user_name}\", level=1)\n",
    "    \n",
    "    # Section 1: Executive Summary\n",
    "    doc.add_heading(\"1. Executive Summary & Overall Performance\", level=2)\n",
    "    doc.add_paragraph().add_run(\"Final Key Metrics (vs. Peers):\").bold = True\n",
    "    for _, row in user_metric_scores.iterrows():\n",
    "        metric_id = row['metric_id']\n",
    "        metric_name = data['metrics'].set_index('id').loc[metric_id, 'name']\n",
    "        if metric_id in peer_stats['metrics'].index:\n",
    "            peer_stat = peer_stats['metrics'].loc[metric_id]\n",
    "            doc.add_paragraph(f\"{metric_name}: {row['current_value']:.2f} (Peer Min: {peer_stat['min']:.2f}, Avg: {peer_stat['mean']:.2f}, Max: {peer_stat['max']:.2f})\", style='List Bullet')\n",
    "    \n",
    "    # ... (rest of summary is the same)\n",
    "    doc.add_paragraph().add_run(\"Key Strengths (Top KCs):\").bold = True\n",
    "    for _, row in user_kc_scores.nlargest(3, 'current_score').iterrows():\n",
    "        kc_name = data['kcs'].set_index('id').loc[row['kc_id'], 'name']\n",
    "        doc.add_paragraph(f\"{kc_name} - Final Score: {row['current_score']}\", style='List Bullet')\n",
    "        \n",
    "    doc.add_paragraph().add_run(\"Areas for Improvement (Lowest KCs):\").bold = True\n",
    "    for _, row in user_kc_scores.nsmallest(3, 'current_score').iterrows():\n",
    "        kc_name = data['kcs'].set_index('id').loc[row['kc_id'], 'name']\n",
    "        doc.add_paragraph(f\"{kc_name} - Final Score: {row['current_score']}\", style='List Bullet')\n",
    "\n",
    "\n",
    "    # Section 2: Goal Analysis\n",
    "    doc.add_heading(\"2. Goal-by-Goal Analysis\", level=2)\n",
    "    for _, goal_row in user_goals.iterrows():\n",
    "        goal_id = goal_row['goal_id']\n",
    "        goal_name = data['goals'].set_index('id').loc[goal_id, 'name']\n",
    "        doc.add_heading(f\"Analysis for Goal: {goal_name}\", level=3)\n",
    "\n",
    "        # Reconstruct the full 9-step decision data\n",
    "        final_attempt_impacts = parse_final_attempt(goal_row['dialogue_history'], data)\n",
    "        # ... (reconstruction logic is the same)\n",
    "        final_attempt_kc_delta = pd.Series(dtype=float)\n",
    "        for _, impacts in final_attempt_impacts.items():\n",
    "            for impact in impacts:\n",
    "                final_attempt_kc_delta[impact['kc_id']] = final_attempt_kc_delta.get(impact['kc_id'], 0) + impact['score_change']\n",
    "        \n",
    "        # Get the user's KC scores *before* this goal started\n",
    "        initial_kc_scores_for_goal = {}\n",
    "        kc_scores_for_goal = user_kc_scores[user_kc_scores['kc_id'].isin(final_attempt_kc_delta.index)]\n",
    "        kc_delta_for_missing_attempts = pd.Series(dtype=float)\n",
    "        for _, kc_row in kc_scores_for_goal.iterrows():\n",
    "            kc_id = kc_row['kc_id']\n",
    "            final_score = kc_row['current_score']\n",
    "            change_from_last_attempt = final_attempt_kc_delta.get(kc_id, 0)\n",
    "            kc_delta_for_missing_attempts[kc_id] = final_score - change_from_last_attempt\n",
    "            initial_kc_scores_for_goal[kc_id] = final_score - final_attempt_kc_delta.get(kc_id, 0) - kc_delta_for_missing_attempts.get(kc_id, 0)\n",
    "        \n",
    "        num_attempts = goal_row['attempts_for_current_goal_cycle']\n",
    "        if num_attempts == 0: num_attempts = 1\n",
    "        num_decisions_per_attempt = 3\n",
    "        num_missing_decisions = (num_attempts - 1) * num_decisions_per_attempt\n",
    "\n",
    "        all_decision_data = []\n",
    "        if num_missing_decisions > 0:\n",
    "            for decision_num in range(1, num_missing_decisions + 1):\n",
    "                for kc_id, total_change in kc_delta_for_missing_attempts.items():\n",
    "                    score_change_per_step = total_change / num_missing_decisions if num_missing_decisions > 0 else 0\n",
    "                    all_decision_data.append({'decision_num': decision_num, 'kc_id': kc_id, 'score_change': score_change_per_step, 'initial_score': initial_kc_scores_for_goal.get(kc_id, 0)})\n",
    "        \n",
    "        start_decision = num_missing_decisions + 1\n",
    "        for i, impacts in sorted(final_attempt_impacts.items()):\n",
    "            decision_num = start_decision + i - 1\n",
    "            for impact in impacts:\n",
    "                all_decision_data.append({'decision_num': decision_num, 'kc_id': impact['kc_id'], 'score_change': impact['score_change'], 'initial_score': initial_kc_scores_for_goal.get(impact['kc_id'], 0)})\n",
    "        \n",
    "        # Add Learning Quadrant\n",
    "        doc.add_heading(\"Learning Quadrant\", level=4)\n",
    "        quadrant_plot = create_learning_quadrant_plot(all_decision_data, data)\n",
    "        if quadrant_plot:\n",
    "            doc.add_picture(quadrant_plot, width=Inches(6.0))\n",
    "        \n",
    "        # Add Performance vs. Learning Charts\n",
    "        doc.add_heading(\"Performance vs. Learning Analysis\", level=4)\n",
    "        for metric_name in METRIC_TO_KC_MAP.keys():\n",
    "            dual_axis_plot = create_dual_axis_plot(all_decision_data, metric_name, data)\n",
    "            if dual_axis_plot:\n",
    "                doc.add_picture(dual_axis_plot, width=Inches(6.0))\n",
    "        doc.add_page_break()\n",
    "\n",
    "    # Section 3: Leaderboard\n",
    "    doc.add_heading(\"3. Learning Performance Leaderboard\", level=2)\n",
    "    doc.add_paragraph(\"This ranks participants by their total cumulative score across all Knowledge Components.\")\n",
    "    leaderboard_table = doc.add_table(rows=1, cols=3)\n",
    "    leaderboard_table.style = 'Table Grid'\n",
    "    hdr_cells = leaderboard_table.rows[0].cells\n",
    "    hdr_cells[0].text = 'Rank'; hdr_cells[1].text = 'Participant'; hdr_cells[2].text = 'Total KC Score'\n",
    "    \n",
    "    for i, (_, row) in enumerate(leaderboard.iterrows()):\n",
    "        cells = leaderboard_table.add_row().cells\n",
    "        cells[0].text = str(i + 1); cells[1].text = row['name']; cells[2].text = f\"{row['current_score']}\"\n",
    "        if row['name'] == user_name:\n",
    "            for cell in cells:\n",
    "                for p in cell.paragraphs:\n",
    "                    for run in p.runs: run.bold = True\n",
    "    \n",
    "    file_name = f\"Learning_Report_{user_name}_alternative.docx\"\n",
    "    doc.save(file_name)\n",
    "    print(f\"Successfully generated report: {file_name}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_data = load_data()\n",
    "    if all_data:\n",
    "        for key in ['user_kc_scores', 'user_metric_scores']:\n",
    "            col_name = 'current_score' if 'kc' in key else 'current_value'\n",
    "            all_data[key][col_name] = pd.to_numeric(all_data[key][col_name], errors='coerce')\n",
    "            all_data[key].dropna(subset=[col_name], inplace=True)\n",
    "        \n",
    "        peer_stats_metrics, leaderboard_data = calculate_peer_stats(all_data['user_metric_scores'], all_data['user_kc_scores'], all_data)\n",
    "        \n",
    "        user_map = all_data['users'][all_data['users']['name'].isin(PARTICIPANT_NAMES)]\n",
    "        \n",
    "        for _, user_row in user_map.iterrows():\n",
    "            generate_report_for_user(user_row, all_data, {'metrics': peer_stats_metrics}, leaderboard_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
