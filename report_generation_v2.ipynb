{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting report generation script...\n",
      "Fetching data for learners starting with 'BT'...\n",
      "Successfully fetched 107 records.\n",
      "Processing raw data...\n",
      "  -> Processing data for BT8BT9 (0dcaf179-58b2-411b-8874-d41c18467735)\n",
      "  -> Processing data for BT15BT16 (1193bb01-6be2-4e97-b603-dda1b811446d)\n",
      "  -> Processing data for BT14 (14b9c968-dc54-4752-a254-8351e461117a)\n",
      "  -> Processing data for BT2 (3184fa5a-11bf-4526-b34b-cfaae969ab29)\n",
      "  -> Processing data for BT4 (3541ed59-254e-41b8-b208-f4c9f7bdb95a)\n",
      "  -> Processing data for BT13 (50730893-f080-4f52-94cb-8b4d438609b8)\n",
      "  -> Processing data for BT7 (63eb2958-1758-4f6d-89f5-2158ac6873f5)\n",
      "  -> Processing data for BT1 (65c037c6-9bdb-4e0d-9f18-ac5d3f7281c9)\n",
      "  -> Processing data for BT11BT12 (701c22f8-fd72-4f51-b46e-d0cadb761db8)\n",
      "  -> Processing data for BT7 (9b65c028-a111-4b49-9bae-1154f9c72326)\n",
      "  -> Processing data for BT5 (bb07dc77-3422-472a-8de3-4cc4ef2fd088)\n",
      "  -> Processing data for BT3+BT6 (d276ef1e-e84d-4b91-b05c-9a55e41d93f5)\n",
      "  -> Processing data for BT10 (d93c7e0c-87a5-4e28-935b-54aa7a9dbb5d)\n",
      "Data processing complete.\n",
      "\n",
      "Generating individual learner reports...\n",
      "  -> Generating report for BT8BT9...\n",
      "  -> Generating report for BT15BT16...\n",
      "  -> Generating report for BT14...\n",
      "  -> Generating report for BT2...\n",
      "  -> Generating report for BT4...\n",
      "  -> Generating report for BT13...\n",
      "  -> Generating report for BT7...\n",
      "  -> Generating report for BT1...\n",
      "  -> Generating report for BT11BT12...\n",
      "  -> Generating report for BT7...\n",
      "  -> Generating report for BT5...\n",
      "  -> Generating report for BT3+BT6...\n",
      "  -> Generating report for BT10...\n",
      "\n",
      "Generating master report...\n",
      "-> Generating Master Report...\n",
      "   Master Report saved.\n",
      "\n",
      "âœ… All reports have been generated and saved in the 'GeneratedReports' folder.\n"
     ]
    }
   ],
   "source": [
    "# generate_reports.py\n",
    "\n",
    "import os\n",
    "import io\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Data and DB Libraries\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from supabase import create_client, Client\n",
    "\n",
    "# Reporting and Plotting Libraries\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# The folder where all reports will be saved\n",
    "OUTPUT_DIR = Path(\"GeneratedReports\")\n",
    "# The prefix for learners we are interested in\n",
    "LEARNER_PREFIX = \"BT\"\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "\n",
    "def add_df_to_doc(doc, df, title=\"\"):\n",
    "    \"\"\"Adds a Pandas DataFrame to a docx document with a title.\"\"\"\n",
    "    if title:\n",
    "        doc.add_heading(title, level=2)\n",
    "    \n",
    "    # Add a table to the document\n",
    "    if df.empty:\n",
    "        doc.add_paragraph(\"No data available.\")\n",
    "        return\n",
    "        \n",
    "    # Reset index if it's not meaningful (like 0, 1, 2, ...)\n",
    "    if isinstance(df.index, pd.RangeIndex):\n",
    "        df_for_table = df.reset_index(drop=True)\n",
    "    else:\n",
    "        df_for_table = df.reset_index()\n",
    "\n",
    "    table = doc.add_table(rows=1, cols=len(df_for_table.columns))\n",
    "    table.style = 'Table Grid'\n",
    "    \n",
    "    # Add the header rows.\n",
    "    for j, col_name in enumerate(df_for_table.columns):\n",
    "        table.cell(0, j).text = str(col_name)\n",
    "\n",
    "    # Add the rest of the data frame\n",
    "    for i, row in df_for_table.iterrows():\n",
    "        row_cells = table.add_row().cells\n",
    "        for j, val in enumerate(row):\n",
    "            row_cells[j].text = str(val)\n",
    "\n",
    "def create_plot_from_df(df, title, y_label, x_col='Decision Point'):\n",
    "    \"\"\"Creates a line plot from a dataframe and returns it as an in-memory image.\"\"\"\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col != x_col:\n",
    "            ax.plot(df[x_col], df[col], marker='o', linestyle='-', label=col)\n",
    "    \n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel(x_col, fontsize=12)\n",
    "    ax.set_ylabel(y_label, fontsize=12)\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    fig.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout to make room for legend\n",
    "    \n",
    "    # Save plot to an in-memory buffer\n",
    "    img_stream = io.BytesIO()\n",
    "    plt.savefig(img_stream, format='png', dpi=300)\n",
    "    plt.close(fig) # Close the plot to free memory\n",
    "    img_stream.seek(0)\n",
    "    return img_stream\n",
    "\n",
    "\n",
    "# --- CORE SCRIPT LOGIC ---\n",
    "\n",
    "def fetch_analytics_data(supabase: Client) -> pd.DataFrame:\n",
    "    \"\"\"Fetches and cleans data from the historical_learning_analytics table.\"\"\"\n",
    "    print(f\"Fetching data for learners starting with '{LEARNER_PREFIX}'...\")\n",
    "    try:\n",
    "        response = supabase.table('historical_learning_analytics').select(\n",
    "            'created_at, user_id, goal_id, scenario_attempt_number, decision_number, kc_scores_after_decision, metric_values_after_decision, users!inner(name)'\n",
    "        ).like(\n",
    "            'users.name', f'{LEARNER_PREFIX}%'\n",
    "        ).order(\n",
    "            'user_id'\n",
    "        ).order(\n",
    "            'created_at', desc=False  # <-- THIS IS THE CORRECTED LINE\n",
    "        ).execute()\n",
    "\n",
    "        if not response.data:\n",
    "            print(\"No data found for the specified learners.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df = pd.DataFrame(response.data)\n",
    "        \n",
    "        # Unpack user name from the nested dictionary\n",
    "        df['user_name'] = df['users'].apply(lambda x: x['name'])\n",
    "        df = df.drop(columns=['users'])\n",
    "        \n",
    "        print(f\"Successfully fetched {len(df)} records.\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def process_learner_data(raw_df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Processes the raw DataFrame into a dictionary of DataFrames, one for each learner.\"\"\"\n",
    "    print(\"Processing raw data...\")\n",
    "    if raw_df.empty:\n",
    "        return {}\n",
    "\n",
    "    all_learners_data = {}\n",
    "    \n",
    "    # Get all unique KC and Metric names across the entire dataset\n",
    "    all_kcs = set()\n",
    "    all_metrics = set()\n",
    "    raw_df['kc_scores_after_decision'].dropna().apply(lambda x: all_kcs.update(x.keys()))\n",
    "    raw_df['metric_values_after_decision'].dropna().apply(lambda x: all_metrics.update(x.keys()))\n",
    "\n",
    "    # Group data by each user\n",
    "    for user_id, group in raw_df.groupby('user_id'):\n",
    "        user_name = group['user_name'].iloc[0]\n",
    "        print(f\"  -> Processing data for {user_name} ({user_id})\")\n",
    "\n",
    "        # Sort chronologically for this user\n",
    "        learner_df = group.sort_values('created_at').reset_index(drop=True)\n",
    "        \n",
    "        # Create a clean 'Decision Point' identifier for plotting\n",
    "        learner_df['Decision Point'] = [f\"G{r.goal_id}-S{r.scenario_attempt_number}-D{r.decision_number}\" for r in learner_df.itertuples()]\n",
    "\n",
    "        # Expand the JSON columns into actual dataframe columns\n",
    "        kc_df = pd.json_normalize(learner_df['kc_scores_after_decision']).reindex(columns=sorted(list(all_kcs))).fillna(0)\n",
    "        metric_df = pd.json_normalize(learner_df['metric_values_after_decision']).reindex(columns=sorted(list(all_metrics))).fillna(0)\n",
    "\n",
    "        # Combine everything into a single, clean DataFrame for the learner\n",
    "        processed_df = pd.concat([\n",
    "            learner_df[['user_id', 'user_name', 'created_at', 'Decision Point']],\n",
    "            kc_df,\n",
    "            metric_df\n",
    "        ], axis=1)\n",
    "\n",
    "        all_learners_data[user_id] = {\n",
    "            \"user_name\": user_name,\n",
    "            \"full_data\": processed_df,\n",
    "            \"all_kcs\": sorted(list(all_kcs)),\n",
    "            \"all_metrics\": sorted(list(all_metrics))\n",
    "        }\n",
    "        \n",
    "    print(\"Data processing complete.\")\n",
    "    return all_learners_data\n",
    "\n",
    "\n",
    "def generate_individual_report(learner_data: dict, output_dir: Path):\n",
    "    \"\"\"Generates a single Word document report for one learner.\"\"\"\n",
    "    user_name = learner_data['user_name']\n",
    "    df = learner_data['full_data']\n",
    "    kcs = learner_data['all_kcs']\n",
    "    metrics = learner_data['all_metrics']\n",
    "    \n",
    "    print(f\"  -> Generating report for {user_name}...\")\n",
    "    \n",
    "    doc = Document()\n",
    "    doc.add_heading(f'Learner Report: {user_name}', 0)\n",
    "    doc.add_paragraph(f\"Report generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "    # --- Section 1: Final Scores ---\n",
    "    doc.add_heading('Final Cumulative Scores', level=1)\n",
    "    final_scores = df.iloc[-1]\n",
    "    \n",
    "    # Final KC Scores Table\n",
    "    final_kc_scores = final_scores[kcs].to_frame(name='Final Score')\n",
    "    final_kc_scores.index.name = \"Knowledge Component (KC)\"\n",
    "    add_df_to_doc(doc, final_kc_scores, \"Final KC Scores\")\n",
    "\n",
    "    # Final Metric Scores Table\n",
    "    final_metric_scores = final_scores[metrics].to_frame(name='Final Value')\n",
    "    final_metric_scores.index.name = \"Metric\"\n",
    "    add_df_to_doc(doc, final_metric_scores, \"Final Metric Scores\")\n",
    "    \n",
    "    doc.add_page_break()\n",
    "\n",
    "    # --- Section 2: Scores Over Time ---\n",
    "    doc.add_heading('Performance Over Time', level=1)\n",
    "    \n",
    "    # KC Scores Progression\n",
    "    kc_progression_df = df[['Decision Point'] + kcs]\n",
    "    add_df_to_doc(doc, kc_progression_df.set_index('Decision Point'), \"KC Scores per Decision Point\")\n",
    "    \n",
    "    kc_plot_img = create_plot_from_df(kc_progression_df, \"KC Scores Over Time\", \"KC Score\")\n",
    "    doc.add_picture(kc_plot_img, width=Inches(6.5))\n",
    "    \n",
    "    # Metric Scores Progression\n",
    "    metric_progression_df = df[['Decision Point'] + metrics]\n",
    "    add_df_to_doc(doc, metric_progression_df.set_index('Decision Point'), \"Metric Values per Decision Point\")\n",
    "    \n",
    "    metric_plot_img = create_plot_from_df(metric_progression_df, \"Metric Values Over Time\", \"Metric Value\")\n",
    "    doc.add_picture(metric_plot_img, width=Inches(6.5))\n",
    "\n",
    "    # --- Save the document ---\n",
    "    file_path = output_dir / f\"Report_{user_name.replace(' ', '_')}.docx\"\n",
    "    doc.save(file_path)\n",
    "\n",
    "\n",
    "def generate_master_report(all_learners_data: dict, output_dir: Path):\n",
    "    \"\"\"Generates the master report with aggregate stats and leaderboards.\"\"\"\n",
    "    print(\"-> Generating Master Report...\")\n",
    "    if not all_learners_data:\n",
    "        print(\"   No data available to generate a master report.\")\n",
    "        return\n",
    "\n",
    "    doc = Document()\n",
    "    doc.add_heading('Master Learner Report', 0)\n",
    "    doc.add_paragraph(f\"Report generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    doc.add_paragraph(f\"This report covers {len(all_learners_data)} learners whose names start with '{LEARNER_PREFIX}'.\")\n",
    "\n",
    "    # --- Compile final scores from all learners into one DataFrame ---\n",
    "    final_scores_list = []\n",
    "    for user_id, data in all_learners_data.items():\n",
    "        final_row = data['full_data'].iloc[-1].copy()\n",
    "        final_scores_list.append(final_row)\n",
    "    \n",
    "    final_scores_df = pd.DataFrame(final_scores_list).set_index('user_name')\n",
    "    kcs = all_learners_data[list(all_learners_data.keys())[0]]['all_kcs']\n",
    "    metrics = all_learners_data[list(all_learners_data.keys())[0]]['all_metrics']\n",
    "\n",
    "    # --- Section 1: Aggregate Statistics ---\n",
    "    doc.add_heading('Aggregate Statistics (Final Scores)', level=1)\n",
    "    \n",
    "    # KC Stats\n",
    "    kc_stats = final_scores_df[kcs].describe().loc[['mean', 'min', 'max']].round(2)\n",
    "    add_df_to_doc(doc, kc_stats, \"KC Score Statistics (Across All Learners)\")\n",
    "\n",
    "    # Metric Stats\n",
    "    metric_stats = final_scores_df[metrics].describe().loc[['mean', 'min', 'max']].round(2)\n",
    "    add_df_to_doc(doc, metric_stats, \"Metric Value Statistics (Across All Learners)\")\n",
    "    \n",
    "    doc.add_page_break()\n",
    "    \n",
    "    # --- Section 2: Leaderboards ---\n",
    "    doc.add_heading('Leaderboards', level=1)\n",
    "    \n",
    "    # KC Leaderboard (based on sum of all final KC scores)\n",
    "    final_scores_df['Total KC Score'] = final_scores_df[kcs].sum(axis=1)\n",
    "    kc_leaderboard = final_scores_df[['Total KC Score']].sort_values('Total KC Score', ascending=False).round(2)\n",
    "    add_df_to_doc(doc, kc_leaderboard.head(10), \"Top 10 - KC Leaderboard (by Sum of Final KC Scores)\")\n",
    "    \n",
    "    # Metric Leaderboard (based on a normalized composite score)\n",
    "    # Normalizing is important because metrics have different scales (e.g., Revenue vs. Reputation)\n",
    "    # We scale each metric to be between 0 and 1, then sum them up for a composite score.\n",
    "    doc.add_paragraph(\n",
    "        \"The Metric Leaderboard is calculated by normalizing each metric (scaling from 0 to 1 based on the min/max in this group) \"\n",
    "        \"and then summing these normalized scores. This gives a balanced view of overall performance across all metrics.\"\n",
    "    )\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_metrics = scaler.fit_transform(final_scores_df[metrics])\n",
    "    final_scores_df['Composite Metric Score'] = pd.DataFrame(normalized_metrics, index=final_scores_df.index).sum(axis=1)\n",
    "    metric_leaderboard = final_scores_df[['Composite Metric Score']].sort_values('Composite Metric Score', ascending=False).round(3)\n",
    "    add_df_to_doc(doc, metric_leaderboard.head(10), \"Top 10 - Metric Leaderboard (by Composite Score)\")\n",
    "\n",
    "    # --- Save the document ---\n",
    "    file_path = output_dir / \"Master_Report.docx\"\n",
    "    doc.save(file_path)\n",
    "    print(\"   Master Report saved.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the entire reporting script.\"\"\"\n",
    "    # --- Setup ---\n",
    "    print(\"Starting report generation script...\")\n",
    "    load_dotenv('.env.local')\n",
    "    \n",
    "    supabase_url = os.environ.get(\"NEXT_PUBLIC_SUPABASE_URL\")\n",
    "    supabase_key = os.environ.get(\"NEXT_PUBLIC_SUPABASE_ANON_KEY\")\n",
    "\n",
    "    if not supabase_url or not supabase_key:\n",
    "        print(\"Error: Supabase URL or Key not found in .env.local file.\")\n",
    "        print(\"Please create a .env.local file with your credentials.\")\n",
    "        return\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Initialize Supabase client\n",
    "    supabase: Client = create_client(supabase_url, supabase_key)\n",
    "\n",
    "    # --- Data Fetching and Processing ---\n",
    "    raw_df = fetch_analytics_data(supabase)\n",
    "    if raw_df.empty:\n",
    "        print(\"Exiting script as no data was fetched.\")\n",
    "        return\n",
    "        \n",
    "    all_learners_data = process_learner_data(raw_df)\n",
    "    \n",
    "    if not all_learners_data:\n",
    "        print(\"Exiting script as no learner data could be processed.\")\n",
    "        return\n",
    "\n",
    "    # --- Report Generation ---\n",
    "    print(\"\\nGenerating individual learner reports...\")\n",
    "    for user_id in all_learners_data:\n",
    "        generate_individual_report(all_learners_data[user_id], OUTPUT_DIR)\n",
    "    \n",
    "    print(\"\\nGenerating master report...\")\n",
    "    generate_master_report(all_learners_data, OUTPUT_DIR)\n",
    "    \n",
    "    print(f\"\\nâœ… All reports have been generated and saved in the '{OUTPUT_DIR}' folder.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting report generation script...\n",
      "Fetching data for learners starting with 'BT'...\n",
      "Successfully fetched 107 records.\n",
      "Processing raw data...\n",
      "  -> Processing data for BT8BT9 on Goal: 'Break Even and Build Trust'\n",
      "  -> Processing data for BT15BT16 on Goal: 'Break Even and Build Trust'\n",
      "  -> Processing data for BT14 on Goal: 'Price with Purpose'\n",
      "  -> Processing data for BT2 on Goal: 'Break Even and Build Trust'\n",
      "  -> Processing data for BT4 on Goal: 'Break Even and Build Trust'\n",
      "  -> Processing data for BT13 on Goal: 'Price with Purpose'\n",
      "  -> Processing data for BT7 on Goal: 'Price with Purpose'\n",
      "  -> Processing data for BT1 on Goal: 'Break Even and Build Trust'\n",
      "  -> Processing data for BT11BT12 on Goal: 'Price with Purpose'\n",
      "  -> Processing data for BT7 on Goal: 'Price with Purpose'\n",
      "  -> Processing data for BT5 on Goal: 'Price with Purpose'\n",
      "  -> Processing data for BT3+BT6 on Goal: 'Price with Purpose'\n",
      "  -> Processing data for BT10 on Goal: 'Break Even and Build Trust'\n",
      "Data processing complete.\n",
      "Calculating aggregate statistics...\n",
      "\n",
      "Generating individual learner reports...\n",
      "  -> Generating report for BT8BT9 (Goal: Break Even and Build Trust)...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "assigned style is type CHARACTER (2), need type PARAGRAPH (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 376\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mâœ… All reports have been generated and saved in the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m folder.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 376\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 360\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGenerating individual learner reports...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m all_learners_data\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m--> 360\u001b[0m     \u001b[43mgenerate_individual_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magg_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# Generate master report\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGenerating master report...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 224\u001b[0m, in \u001b[0;36mgenerate_individual_report\u001b[1;34m(learner_data, agg_stats, output_dir)\u001b[0m\n\u001b[0;32m    222\u001b[0m doc \u001b[38;5;241m=\u001b[39m Document()\n\u001b[0;32m    223\u001b[0m doc\u001b[38;5;241m.\u001b[39madd_heading(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearner Report: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 224\u001b[0m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_paragraph\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGoal Attempted: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgoal_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEmphasis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m doc\u001b[38;5;241m.\u001b[39madd_paragraph(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReport generated on: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# --- Section 1: Final Scores with Comparison ---\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\ipl\\Lib\\site-packages\\docx\\document.py:69\u001b[0m, in \u001b[0;36mDocument.add_paragraph\u001b[1;34m(self, text, style)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_paragraph\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, style: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m ParagraphStyle \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Paragraph:\n\u001b[0;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return paragraph newly added to the end of the document.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m    The paragraph is populated with `text` and having paragraph style `style`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    break.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_body\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_paragraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\ipl\\Lib\\site-packages\\docx\\blkcntnr.py:57\u001b[0m, in \u001b[0;36mBlockItemContainer.add_paragraph\u001b[1;34m(self, text, style)\u001b[0m\n\u001b[0;32m     55\u001b[0m     paragraph\u001b[38;5;241m.\u001b[39madd_run(text)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m style \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[43mparagraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m \u001b[38;5;241m=\u001b[39m style\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m paragraph\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\ipl\\Lib\\site-packages\\docx\\text\\paragraph.py:146\u001b[0m, in \u001b[0;36mParagraph.style\u001b[1;34m(self, style_or_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;129m@style\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstyle\u001b[39m(\u001b[38;5;28mself\u001b[39m, style_or_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m ParagraphStyle \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 146\u001b[0m     style_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_style_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle_or_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWD_STYLE_TYPE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPARAGRAPH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_p\u001b[38;5;241m.\u001b[39mstyle \u001b[38;5;241m=\u001b[39m style_id\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\ipl\\Lib\\site-packages\\docx\\parts\\document.py:80\u001b[0m, in \u001b[0;36mDocumentPart.get_style_id\u001b[1;34m(self, style_or_name, style_type)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_style_id\u001b[39m(\u001b[38;5;28mself\u001b[39m, style_or_name, style_type):\n\u001b[0;32m     73\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the style_id (|str|) of the style of `style_type` matching\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m    `style_or_name`.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    wrong type or names a style not present in the document.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_style_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle_or_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\ipl\\Lib\\site-packages\\docx\\styles\\styles.py:101\u001b[0m, in \u001b[0;36mStyles.get_style_id\u001b[1;34m(self, style_or_name, style_type)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_style_id_from_style(style_or_name, style_type)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_style_id_from_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle_or_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\ipl\\Lib\\site-packages\\docx\\styles\\styles.py:130\u001b[0m, in \u001b[0;36mStyles._get_style_id_from_name\u001b[1;34m(self, style_name, style_type)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_style_id_from_name\u001b[39m(\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m, style_name: \u001b[38;5;28mstr\u001b[39m, style_type: WD_STYLE_TYPE\n\u001b[0;32m    123\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the id of the style of `style_type` corresponding to `style_name`.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03m    Returns |None| if that style is the default style for `style_type`. Raises\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    |ValueError| if the named style is not found in the document or does not match\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    `style_type`.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_style_id_from_style\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mstyle_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\ipl\\Lib\\site-packages\\docx\\styles\\styles.py:140\u001b[0m, in \u001b[0;36mStyles._get_style_id_from_style\u001b[1;34m(self, style, style_type)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Id of `style`, or |None| if it is the default style of `style_type`.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03mRaises |ValueError| if style is not of `style_type`.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m style\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m style_type:\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massigned style is type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, need type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (style\u001b[38;5;241m.\u001b[39mtype, style_type)\n\u001b[0;32m    142\u001b[0m     )\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m style \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault(style_type):\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: assigned style is type CHARACTER (2), need type PARAGRAPH (1)"
     ]
    }
   ],
   "source": [
    "# generate_reports.py\n",
    "\n",
    "import os\n",
    "import io\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Data and DB Libraries\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from supabase import create_client, Client\n",
    "\n",
    "# Reporting and Plotting Libraries\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "OUTPUT_DIR = Path(\"GeneratedReports\")\n",
    "LEARNER_PREFIX = \"BT\"\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "\n",
    "def add_df_to_doc(doc, df, title=\"\"):\n",
    "    \"\"\"Adds a rounded Pandas DataFrame to a docx document with a title.\"\"\"\n",
    "    if title:\n",
    "        doc.add_heading(title, level=2)\n",
    "    \n",
    "    if df.empty:\n",
    "        doc.add_paragraph(\"No data available.\")\n",
    "        return\n",
    "        \n",
    "    # Round all numeric columns to 2 decimal places\n",
    "    df_rounded = df.copy()\n",
    "    for col in df_rounded.select_dtypes(include=['number']).columns:\n",
    "        df_rounded[col] = df_rounded[col].round(2)\n",
    "\n",
    "    # Reset index if it's a simple range, otherwise keep it as a column\n",
    "    if isinstance(df_rounded.index, pd.RangeIndex):\n",
    "        df_for_table = df_rounded.reset_index(drop=True)\n",
    "    else:\n",
    "        df_for_table = df_rounded.reset_index()\n",
    "\n",
    "    table = doc.add_table(rows=1, cols=len(df_for_table.columns))\n",
    "    table.style = 'Table Grid'\n",
    "    \n",
    "    for j, col_name in enumerate(df_for_table.columns):\n",
    "        table.cell(0, j).text = str(col_name)\n",
    "\n",
    "    for i, row in df_for_table.iterrows():\n",
    "        row_cells = table.add_row().cells\n",
    "        for j, val in enumerate(row):\n",
    "            row_cells[j].text = str(val)\n",
    "\n",
    "def create_plot_from_df(df, title, y_label, x_col='Decision Point'):\n",
    "    \"\"\"Creates a line plot from a dataframe and returns it as an in-memory image.\"\"\"\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(10, 5.5))\n",
    "    \n",
    "    # Plotting logic\n",
    "    for col in df.columns:\n",
    "        if col != x_col:\n",
    "            ax.plot(df[x_col], df[col], marker='o', linestyle='-', label=col)\n",
    "    \n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel(x_col, fontsize=12)\n",
    "    ax.set_ylabel(y_label, fontsize=12)\n",
    "    \n",
    "    # Adjust legend and layout\n",
    "    if len(df.columns) > 2: # More than one line to plot\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        fig.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "    else:\n",
    "        fig.tight_layout()\n",
    "        \n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    img_stream = io.BytesIO()\n",
    "    plt.savefig(img_stream, format='png', dpi=300)\n",
    "    plt.close(fig)\n",
    "    img_stream.seek(0)\n",
    "    return img_stream\n",
    "\n",
    "# --- CORE SCRIPT LOGIC ---\n",
    "\n",
    "def fetch_analytics_data(supabase: Client) -> pd.DataFrame:\n",
    "    \"\"\"Fetches and cleans data, including the goal name.\"\"\"\n",
    "    print(f\"Fetching data for learners starting with '{LEARNER_PREFIX}'...\")\n",
    "    try:\n",
    "        # UPDATED QUERY: Joins with goals table to get goal name\n",
    "        response = supabase.table('historical_learning_analytics').select(\n",
    "            'created_at, user_id, goal_id, scenario_attempt_number, decision_number, '\n",
    "            'kc_scores_after_decision, metric_values_after_decision, '\n",
    "            'users!inner(name), goals!inner(name)'\n",
    "        ).like(\n",
    "            'users.name', f'{LEARNER_PREFIX}%'\n",
    "        ).order(\n",
    "            'user_id'\n",
    "        ).order(\n",
    "            'created_at', desc=False\n",
    "        ).execute()\n",
    "\n",
    "        if not response.data:\n",
    "            print(\"No data found for the specified learners.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df = pd.DataFrame(response.data)\n",
    "        \n",
    "        # Unpack nested data\n",
    "        df['user_name'] = df['users'].apply(lambda x: x['name'])\n",
    "        df['goal_name'] = df['goals'].apply(lambda x: x['name'])\n",
    "        df = df.drop(columns=['users', 'goals'])\n",
    "        \n",
    "        # Convert created_at to datetime objects for proper sorting\n",
    "        df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "        \n",
    "        print(f\"Successfully fetched {len(df)} records.\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def process_learner_data(raw_df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Processes raw data, adds a 'Genesis' point, and structures it by learner.\"\"\"\n",
    "    print(\"Processing raw data...\")\n",
    "    if raw_df.empty:\n",
    "        return {}\n",
    "\n",
    "    all_learners_data = {}\n",
    "    \n",
    "    # Get all unique KC and Metric names across the entire dataset\n",
    "    all_kcs = set()\n",
    "    all_metrics = set()\n",
    "    raw_df['kc_scores_after_decision'].dropna().apply(lambda x: all_kcs.update(x.keys()))\n",
    "    raw_df['metric_values_after_decision'].dropna().apply(lambda x: all_metrics.update(x.keys()))\n",
    "    all_kcs, all_metrics = sorted(list(all_kcs)), sorted(list(all_metrics))\n",
    "\n",
    "    for (user_id, goal_id), group in raw_df.groupby(['user_id', 'goal_id']):\n",
    "        user_name = group['user_name'].iloc[0]\n",
    "        goal_name = group['goal_name'].iloc[0]\n",
    "        \n",
    "        print(f\"  -> Processing data for {user_name} on Goal: '{goal_name}'\")\n",
    "\n",
    "        learner_df = group.sort_values('created_at').reset_index(drop=True)\n",
    "        \n",
    "        # Expand JSON columns\n",
    "        kc_df = pd.json_normalize(learner_df['kc_scores_after_decision']).reindex(columns=all_kcs).fillna(0)\n",
    "        metric_df = pd.json_normalize(learner_df['metric_values_after_decision']).reindex(columns=all_metrics).fillna(0)\n",
    "        \n",
    "        # Create a clean 'Decision Point' identifier\n",
    "        learner_df['Decision Point'] = [f\"G{r.goal_id}-S{r.scenario_attempt_number}-D{r.decision_number}\" for r in learner_df.itertuples()]\n",
    "\n",
    "        # --- ADD GENESIS POINT ---\n",
    "        genesis_row = {\n",
    "            'created_at': learner_df['created_at'].iloc[0] - timedelta(seconds=1),\n",
    "            'Decision Point': 'Genesis',\n",
    "            **{kc: 0 for kc in all_kcs},\n",
    "            **{metric: 0 for metric in all_metrics}\n",
    "        }\n",
    "        genesis_df = pd.DataFrame([genesis_row])\n",
    "        \n",
    "        # Combine everything into a clean DataFrame for the learner\n",
    "        base_info = learner_df[['created_at', 'Decision Point']]\n",
    "        processed_df = pd.concat([base_info, kc_df, metric_df], axis=1)\n",
    "        \n",
    "        # Prepend the Genesis row\n",
    "        full_df = pd.concat([genesis_df, processed_df], ignore_index=True)\n",
    "        \n",
    "        # Identify active KCs and Metrics (ones that changed from 0)\n",
    "        final_scores = full_df.iloc[-1]\n",
    "        active_kcs = [kc for kc in all_kcs if final_scores[kc] != 0]\n",
    "        active_metrics = [metric for metric in all_metrics if final_scores[metric] != 0]\n",
    "\n",
    "        all_learners_data[f\"{user_id}_{goal_id}\"] = {\n",
    "            \"user_name\": user_name,\n",
    "            \"goal_name\": goal_name,\n",
    "            \"full_data\": full_df,\n",
    "            \"all_kcs\": all_kcs,\n",
    "            \"all_metrics\": all_metrics,\n",
    "            \"active_kcs\": active_kcs,\n",
    "            \"active_metrics\": active_metrics\n",
    "        }\n",
    "        \n",
    "    print(\"Data processing complete.\")\n",
    "    return all_learners_data\n",
    "\n",
    "def calculate_aggregate_stats(all_learners_data: dict) -> dict:\n",
    "    \"\"\"Calculates aggregate statistics (mean, min, max) across all learners.\"\"\"\n",
    "    print(\"Calculating aggregate statistics...\")\n",
    "    if not all_learners_data:\n",
    "        return {}\n",
    "\n",
    "    final_scores_list = []\n",
    "    for data in all_learners_data.values():\n",
    "        final_row = data['full_data'].iloc[-1].copy()\n",
    "        final_row['user_name'] = data['user_name']\n",
    "        final_scores_list.append(final_row)\n",
    "    \n",
    "    if not final_scores_list:\n",
    "        return {}\n",
    "\n",
    "    final_scores_df = pd.DataFrame(final_scores_list).set_index('user_name')\n",
    "    kcs = all_learners_data[list(all_learners_data.keys())[0]]['all_kcs']\n",
    "    metrics = all_learners_data[list(all_learners_data.keys())[0]]['all_metrics']\n",
    "\n",
    "    kc_stats = final_scores_df[kcs].describe().loc[['mean', 'min', 'max']]\n",
    "    metric_stats = final_scores_df[metrics].describe().loc[['mean', 'min', 'max']]\n",
    "\n",
    "    return {\"kc\": kc_stats, \"metric\": metric_stats, \"final_scores_df\": final_scores_df}\n",
    "\n",
    "def generate_individual_report(learner_data: dict, agg_stats: dict, output_dir: Path):\n",
    "    \"\"\"Generates a single, enhanced Word document report for one learner.\"\"\"\n",
    "    user_name = learner_data['user_name']\n",
    "    goal_name = learner_data['goal_name']\n",
    "    df = learner_data['full_data']\n",
    "    active_kcs = learner_data['active_kcs']\n",
    "    active_metrics = learner_data['active_metrics']\n",
    "    \n",
    "    print(f\"  -> Generating report for {user_name} (Goal: {goal_name})...\")\n",
    "    \n",
    "    doc = Document()\n",
    "    doc.add_heading(f'Learner Report: {user_name}', 0)\n",
    "    \n",
    "    # --- THIS IS THE CORRECTED LINE ---\n",
    "    # Use 'Quote' which is a built-in paragraph style, often italicized.\n",
    "    doc.add_paragraph(f\"Goal Attempted: {goal_name}\", style='Quote') \n",
    "    # --- END OF CORRECTION ---\n",
    "\n",
    "    doc.add_paragraph(f\"Report generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "    # --- Section 1: Final Scores with Comparison ---\n",
    "    doc.add_heading('Final Cumulative Scores', level=1)\n",
    "    doc.add_paragraph(\"This section shows the learner's final score for each item compared to the class average, minimum, and maximum.\")\n",
    "    \n",
    "    final_scores = df.iloc[-1]\n",
    "\n",
    "    # Enhanced Final KC Scores Table\n",
    "    if active_kcs:\n",
    "        kc_summary = final_scores[active_kcs].to_frame(name='Your Score')\n",
    "        kc_summary = kc_summary.join(agg_stats['kc'][active_kcs].T.rename(columns={'mean': 'Class Avg', 'min': 'Class Min', 'max': 'Class Max'}))\n",
    "        kc_summary.index.name = \"Knowledge Component (KC)\"\n",
    "        add_df_to_doc(doc, kc_summary, \"Final KC Scores\")\n",
    "\n",
    "    # Enhanced Final Metric Scores Table\n",
    "    if active_metrics:\n",
    "        metric_summary = final_scores[active_metrics].to_frame(name='Your Value')\n",
    "        metric_summary = metric_summary.join(agg_stats['metric'][active_metrics].T.rename(columns={'mean': 'Class Avg', 'min': 'Class Min', 'max': 'Class Max'}))\n",
    "        metric_summary.index.name = \"Metric\"\n",
    "        add_df_to_doc(doc, metric_summary, \"Final Metric Values\")\n",
    "    \n",
    "    doc.add_page_break()\n",
    "\n",
    "    # --- Section 2: Scores Over Time ---\n",
    "    doc.add_heading('Performance Over Time', level=1)\n",
    "    \n",
    "    # KC Scores Progression\n",
    "    if active_kcs:\n",
    "        kc_progression_df = df[['Decision Point'] + active_kcs]\n",
    "        add_df_to_doc(doc, kc_progression_df.set_index('Decision Point'), \"KC Scores per Decision Point\")\n",
    "        kc_plot_img = create_plot_from_df(kc_progression_df, \"KC Scores Over Time\", \"KC Score\")\n",
    "        doc.add_picture(kc_plot_img, width=Inches(6.5))\n",
    "    \n",
    "    # Metric Scores Progression (SPLIT PLOTS)\n",
    "    if active_metrics:\n",
    "        metric_progression_df = df[['Decision Point'] + active_metrics]\n",
    "        add_df_to_doc(doc, metric_progression_df.set_index('Decision Point'), \"Metric Values per Decision Point\")\n",
    "\n",
    "        # Revenue Plot\n",
    "        if 'Revenue' in active_metrics:\n",
    "            revenue_df = df[['Decision Point', 'Revenue']]\n",
    "            revenue_plot_img = create_plot_from_df(revenue_df, \"Revenue Over Time\", \"Revenue Value\")\n",
    "            doc.add_heading(\"Revenue Progression\", level=3)\n",
    "            doc.add_picture(revenue_plot_img, width=Inches(6.5))\n",
    "\n",
    "        # Other Metrics Plot\n",
    "        other_metrics = [m for m in active_metrics if m != 'Revenue']\n",
    "        if other_metrics:\n",
    "            other_metrics_df = df[['Decision Point'] + other_metrics]\n",
    "            other_metrics_plot_img = create_plot_from_df(other_metrics_df, \"Other Metric Values Over Time\", \"Metric Value\")\n",
    "            doc.add_heading(\"Other Metrics Progression\", level=3)\n",
    "            doc.add_picture(other_metrics_plot_img, width=Inches(6.5))\n",
    "\n",
    "    file_path = output_dir / f\"Report_{user_name.replace(' ', '_')}_{goal_name.replace(' ', '_')}.docx\"\n",
    "    doc.save(file_path)\n",
    "\n",
    "def generate_master_report(agg_stats: dict, all_kcs: list, all_metrics: list, num_learners: int, output_dir: Path):\n",
    "    \"\"\"Generates the master report with aggregate stats and leaderboards.\"\"\"\n",
    "    print(\"-> Generating Master Report...\")\n",
    "    if not agg_stats:\n",
    "        print(\"   No data available to generate a master report.\")\n",
    "        return\n",
    "\n",
    "    doc = Document()\n",
    "    doc.add_heading('Master Learner Report', 0)\n",
    "    doc.add_paragraph(f\"Report generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    doc.add_paragraph(f\"This report covers {num_learners} learner-goal attempts for names starting with '{LEARNER_PREFIX}'.\")\n",
    "\n",
    "    # --- Section 1: Aggregate Statistics ---\n",
    "    doc.add_heading('Aggregate Statistics (Final Scores)', level=1)\n",
    "    add_df_to_doc(doc, agg_stats['kc'].T, \"KC Score Statistics (Across All Learners)\")\n",
    "    add_df_to_doc(doc, agg_stats['metric'].T, \"Metric Value Statistics (Across All Learners)\")\n",
    "    \n",
    "    doc.add_page_break()\n",
    "    \n",
    "    # --- Section 2: Leaderboards ---\n",
    "    doc.add_heading('Leaderboards', level=1)\n",
    "    final_scores_df = agg_stats['final_scores_df']\n",
    "    \n",
    "    # KC Leaderboard\n",
    "    final_scores_df['Total KC Score'] = final_scores_df[all_kcs].sum(axis=1)\n",
    "    kc_leaderboard = final_scores_df[['Total KC Score']].sort_values('Total KC Score', ascending=False)\n",
    "    add_df_to_doc(doc, kc_leaderboard.head(10), \"Top 10 - KC Leaderboard (by Sum of Final KC Scores)\")\n",
    "    \n",
    "    # Metric Leaderboard\n",
    "    try:\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        scaler = MinMaxScaler()\n",
    "        normalized_metrics = scaler.fit_transform(final_scores_df[all_metrics])\n",
    "        final_scores_df['Composite Metric Score'] = pd.DataFrame(normalized_metrics, index=final_scores_df.index).sum(axis=1)\n",
    "        metric_leaderboard = final_scores_df[['Composite Metric Score']].sort_values('Composite Metric Score', ascending=False)\n",
    "        \n",
    "        doc.add_paragraph(\n",
    "            \"The Metric Leaderboard is calculated by normalizing each metric (scaling from 0 to 1 based on the min/max in this group) \"\n",
    "            \"and then summing these normalized scores. This gives a balanced view of overall performance across all metrics.\"\n",
    "        )\n",
    "        add_df_to_doc(doc, metric_leaderboard.head(10), \"Top 10 - Metric Leaderboard (by Composite Score)\")\n",
    "    except ImportError:\n",
    "        doc.add_paragraph(\"Metric Leaderboard could not be generated. Please install scikit-learn: pip install scikit-learn\")\n",
    "\n",
    "    doc.save(output_dir / \"Master_Report.docx\")\n",
    "    print(\"   Master Report saved.\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the entire reporting script.\"\"\"\n",
    "    print(\"Starting report generation script...\")\n",
    "    load_dotenv('.env.local')\n",
    "    \n",
    "    supabase_url = os.environ.get(\"NEXT_PUBLIC_SUPABASE_URL\")\n",
    "    supabase_key = os.environ.get(\"NEXT_PUBLIC_SUPABASE_ANON_KEY\")\n",
    "\n",
    "    if not supabase_url or not supabase_key:\n",
    "        print(\"Error: Supabase URL or Key not found. Please check your .env.local file.\")\n",
    "        return\n",
    "\n",
    "    OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "    supabase: Client = create_client(supabase_url, supabase_key)\n",
    "\n",
    "    raw_df = fetch_analytics_data(supabase)\n",
    "    if raw_df.empty:\n",
    "        print(\"Exiting script as no data was fetched.\")\n",
    "        return\n",
    "        \n",
    "    all_learners_data = process_learner_data(raw_df)\n",
    "    if not all_learners_data:\n",
    "        print(\"Exiting script as no learner data could be processed.\")\n",
    "        return\n",
    "\n",
    "    # Calculate aggregate stats once\n",
    "    agg_stats = calculate_aggregate_stats(all_learners_data)\n",
    "\n",
    "    # Generate individual reports\n",
    "    print(\"\\nGenerating individual learner reports...\")\n",
    "    for data in all_learners_data.values():\n",
    "        generate_individual_report(data, agg_stats, OUTPUT_DIR)\n",
    "    \n",
    "    # Generate master report\n",
    "    print(\"\\nGenerating master report...\")\n",
    "    first_learner = all_learners_data[list(all_learners_data.keys())[0]]\n",
    "    generate_master_report(\n",
    "        agg_stats, \n",
    "        first_learner['all_kcs'], \n",
    "        first_learner['all_metrics'], \n",
    "        len(all_learners_data), \n",
    "        OUTPUT_DIR\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ… All reports have been generated and saved in the '{OUTPUT_DIR}' folder.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
